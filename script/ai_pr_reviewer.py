#!/usr/bin/env python3
"""
AI PR Code Reviewer - Hybrid (GLM + Gemini)
===========================================

GLM-4-Flashì™€ Gemini 2.5 Flashë¥¼ ë™ì‹œì— ì‚¬ìš©í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ PR ì½”ë“œ ë¦¬ë·° ë´‡.
ë‘ AIì˜ ë¦¬ë·°ë¥¼ ë³‘í•©í•˜ì—¬ ë” ì •í™•í•˜ê³  í¬ê´„ì ì¸ ì½”ë“œ ë¦¬ë·°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

Features:
- ğŸ”¥ GLM-4-Flash (Zhipu AI): ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ì½”ë“œ ë¶„ì„
- âš¡ Gemini 2.5 Flash: ì•ˆì •ì„± + ë¹ ë¥¸ ì‘ë‹µ + 1M ì»¨í…ìŠ¤íŠ¸
- ğŸ”„ ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ë¹ ë¥¸ ë¦¬ë·°
- ğŸ“Š ë‘ AI ì˜ê²¬ ë³‘í•© ë° í•©ì˜ ë„ì¶œ
- ğŸ›¡ï¸ í´ë°± ì§€ì› (í•œ ìª½ ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ìª½ ì‚¬ìš©)
- ğŸ“¦ íŒŒì¼ë³„ ì²­í‚¹: í° diffë¥¼ ìë™ìœ¼ë¡œ íŒŒì¼ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ë¦¬ë·°

Usage:
    # ê¸°ë³¸ ì‚¬ìš©
    python script/ai_pr_reviewer.py --pr 123
    python script/ai_pr_reviewer.py --diff "$(git diff main)"

    # ë‹¨ì¼ AIë§Œ ì‚¬ìš©
    python script/ai_pr_reviewer.py --pr 123 --gemini-only
    python script/ai_pr_reviewer.py --pr 123 --glm-only

    # ì²­í‚¹ ì œì–´
    python script/ai_pr_reviewer.py --pr 123 --no-chunk        # ì²­í‚¹ ë¹„í™œì„±í™”
    python script/ai_pr_reviewer.py --pr 123 --chunk-threshold 50000  # ì„ê³„ê°’ ë³€ê²½

Environment Variables:
    GLM_API_KEY: Zhipu AI API í‚¤ (ë˜ëŠ” ZHIPU_API_KEY)
    GEMINI_API_KEY: Google Gemini API í‚¤ (ë˜ëŠ” GOOGLE_API_KEY)
    GITHUB_TOKEN: GitHub API í† í° (PR ì½”ë©˜íŠ¸ìš©)
"""

import os
import json
import subprocess
import argparse
import asyncio
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict, field
from enum import Enum
from concurrent.futures import ThreadPoolExecutor, as_completed
import re

# Optional imports - graceful degradation
import sys
import io

# Windows ì½˜ì†” ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    print("[WARN] google-generativeai not installed. Gemini will be disabled.")

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("[WARN] openai package not installed. GLM will be disabled.")


# ============================================================================
# Diff Chunking - íŒŒì¼ë³„ ë¶„ë¦¬
# ============================================================================

@dataclass
class DiffChunk:
    """íŒŒì¼ë³„ diff ì²­í¬"""
    file_path: str
    content: str
    size: int

    @property
    def is_code_file(self) -> bool:
        """ì½”ë“œ íŒŒì¼ ì—¬ë¶€ (ë¦¬ë·° ëŒ€ìƒ)"""
        code_extensions = {'.kt', '.java', '.py', '.ts', '.tsx', '.js', '.jsx', '.swift', '.go', '.rs'}
        return any(self.file_path.endswith(ext) for ext in code_extensions)


def parse_diff_by_files(diff: str) -> List[DiffChunk]:
    """
    Git diffë¥¼ íŒŒì¼ë³„ë¡œ ë¶„ë¦¬

    Returns:
        List[DiffChunk]: íŒŒì¼ë³„ diff ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    chunks = []

    # diff --git a/path/file b/path/file íŒ¨í„´ìœ¼ë¡œ ë¶„ë¦¬
    pattern = r'^diff --git a/(.+?) b/(.+?)$'

    # ê° íŒŒì¼ì˜ ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸°
    file_starts = []
    for match in re.finditer(pattern, diff, re.MULTILINE):
        file_starts.append({
            'start': match.start(),
            'file_path': match.group(2)  # b/path ì‚¬ìš©
        })

    if not file_starts:
        # diff í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš° ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì²­í¬ë¡œ
        return [DiffChunk(file_path="unknown", content=diff, size=len(diff))]

    # ê° íŒŒì¼ì˜ diff ë‚´ìš© ì¶”ì¶œ
    for i, file_info in enumerate(file_starts):
        start = file_info['start']
        end = file_starts[i + 1]['start'] if i + 1 < len(file_starts) else len(diff)

        content = diff[start:end].strip()
        chunks.append(DiffChunk(
            file_path=file_info['file_path'],
            content=content,
            size=len(content)
        ))

    return chunks


def group_chunks_by_size(chunks: List[DiffChunk], max_size: int = 30000) -> List[List[DiffChunk]]:
    """
    ì²­í¬ë“¤ì„ max_size ì´í•˜ë¡œ ê·¸ë£¹í™”

    Args:
        chunks: íŒŒì¼ë³„ diff ì²­í¬ ë¦¬ìŠ¤íŠ¸
        max_size: ê·¸ë£¹ë‹¹ ìµœëŒ€ í¬ê¸° (ê¸°ë³¸ 30KB)

    Returns:
        ê·¸ë£¹í™”ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
    """
    groups = []
    current_group = []
    current_size = 0

    # ì½”ë“œ íŒŒì¼ë§Œ í•„í„°ë§ (ì„¤ì • íŒŒì¼ ë“± ì œì™¸)
    code_chunks = [c for c in chunks if c.is_code_file]

    # í¬ê¸°ìˆœ ì •ë ¬ (í° íŒŒì¼ ë¨¼ì € - bin packing)
    sorted_chunks = sorted(code_chunks, key=lambda x: x.size, reverse=True)

    for chunk in sorted_chunks:
        # ë‹¨ì¼ íŒŒì¼ì´ max_size ì´ˆê³¼í•˜ë©´ ë³„ë„ ê·¸ë£¹
        if chunk.size > max_size:
            if current_group:
                groups.append(current_group)
                current_group = []
                current_size = 0
            groups.append([chunk])
            continue

        # í˜„ì¬ ê·¸ë£¹ì— ì¶”ê°€ ê°€ëŠ¥í•˜ë©´ ì¶”ê°€
        if current_size + chunk.size <= max_size:
            current_group.append(chunk)
            current_size += chunk.size
        else:
            # ìƒˆ ê·¸ë£¹ ì‹œì‘
            if current_group:
                groups.append(current_group)
            current_group = [chunk]
            current_size = chunk.size

    if current_group:
        groups.append(current_group)

    return groups


def merge_chunks_to_diff(chunks: List[DiffChunk]) -> str:
    """ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ diff ë¬¸ìì—´ë¡œ ë³‘í•©"""
    return "\n\n".join(chunk.content for chunk in chunks)


class Severity(Enum):
    """ë¦¬ë·° ì´ìŠˆ ì‹¬ê°ë„"""
    CRITICAL = "critical"  # ğŸ”´ ë³´ì•ˆ, ë²„ê·¸, í¬ë˜ì‹œ
    HIGH = "high"          # ğŸŸ  ì„±ëŠ¥, ì•„í‚¤í…ì²˜
    MEDIUM = "medium"      # ğŸŸ¡ ì½”ë“œ ìŠ¤íƒ€ì¼, ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
    LOW = "low"            # ğŸŸ¢ ì œì•ˆ, ê°œì„ ì‚¬í•­
    INFO = "info"          # â„¹ï¸ ì •ë³´ì„± ì½”ë©˜íŠ¸


@dataclass
class ReviewIssue:
    """ì½”ë“œ ë¦¬ë·° ì´ìŠˆ"""
    file_path: str
    line_number: Optional[int]
    severity: Severity
    category: str  # security, performance, bug, style, suggestion
    title: str
    description: str
    suggestion: Optional[str] = None
    source: str = "unknown"  # glm, gemini, merged


@dataclass
class ReviewResult:
    """AI ë¦¬ë·° ê²°ê³¼"""
    provider: str
    success: bool
    issues: List[ReviewIssue] = field(default_factory=list)
    summary: str = ""
    raw_response: str = ""
    error: Optional[str] = None


@dataclass
class MergedReview:
    """ë³‘í•©ëœ ìµœì¢… ë¦¬ë·°"""
    glm_result: Optional[ReviewResult]
    gemini_result: Optional[ReviewResult]
    merged_issues: List[ReviewIssue] = field(default_factory=list)
    consensus_issues: List[ReviewIssue] = field(default_factory=list)  # ë‘ AI ëª¨ë‘ ì§€ì 
    summary: str = ""
    stats: Dict[str, int] = field(default_factory=dict)


class GLMReviewer:
    """GLM-4-Flash ê¸°ë°˜ ì½”ë“œ ë¦¬ë·°ì–´ (Zhipu AI)"""

    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.environ.get("GLM_API_KEY") or os.environ.get("ZHIPU_API_KEY")
        self.client = None

        if self.api_key and OPENAI_AVAILABLE:
            # GLMì€ OpenAI í˜¸í™˜ API ì œê³µ
            self.client = OpenAI(
                api_key=self.api_key,
                base_url="https://open.bigmodel.cn/api/paas/v4/"
            )
    
    @property
    def is_available(self) -> bool:
        return self.client is not None
    
    def review(self, diff: str, context: Dict[str, Any] = None) -> ReviewResult:
        """GLMìœ¼ë¡œ ì½”ë“œ ë¦¬ë·° ìˆ˜í–‰"""
        if not self.is_available:
            return ReviewResult(
                provider="glm",
                success=False,
                error="GLM API not configured"
            )

        try:
            prompt = self._build_prompt(diff, context)

            response = self.client.chat.completions.create(
                model="glm-4-flash",
                messages=[
                    {"role": "system", "content": self._get_system_prompt()},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=4096,
                temperature=0.1
            )

            raw_response = response.choices[0].message.content
            issues = self._parse_response(raw_response)

            return ReviewResult(
                provider="glm",
                success=True,
                issues=issues,
                summary=self._extract_summary(raw_response),
                raw_response=raw_response
            )
            
        except Exception as e:
            return ReviewResult(
                provider="glm",
                success=False,
                error=str(e)
            )
    
    def _get_system_prompt(self) -> str:
        return """You are an expert code reviewer for FanPulse, a K-POP fan platform.

Tech Stack:
- Backend: Kotlin + Spring Boot 3.2 + PostgreSQL + MongoDB + Redis
- Frontend: Next.js + TypeScript + TailwindCSS
- Mobile: Android (Jetpack Compose), iOS (UIKit/SwiftUI)

Review Guidelines:
1. Focus on REAL bugs and security issues first
2. Check for performance problems (N+1 queries, memory leaks)
3. Verify error handling and edge cases
4. Suggest improvements for code quality

Output Format (JSON):
{
  "summary": "Brief overall assessment",
  "issues": [
    {
      "file": "path/to/file.kt",
      "line": 42,
      "severity": "critical|high|medium|low",
      "category": "security|bug|performance|style|suggestion",
      "title": "Short issue title",
      "description": "Detailed explanation",
      "suggestion": "How to fix (optional)"
    }
  ]
}

Be specific with file paths and line numbers when possible.
Focus on actionable feedback, not nitpicks."""
    
    def _build_prompt(self, diff: str, context: Dict[str, Any] = None) -> str:
        MAX_DIFF_SIZE = 30000
        truncated = len(diff) > MAX_DIFF_SIZE

        if truncated:
            print(f"[WARN] GLM: Diff truncated ({len(diff)} -> {MAX_DIFF_SIZE} chars)")
            diff_content = diff[:MAX_DIFF_SIZE] + "\n\n[... truncated, showing first 30KB ...]"
        else:
            diff_content = diff

        prompt = f"Review this code change:\n\n```diff\n{diff_content}\n```"

        if context:
            if context.get("pr_title"):
                prompt = f"PR: {context['pr_title']}\n\n" + prompt
            if context.get("pr_description"):
                prompt += f"\n\nPR Description: {context['pr_description']}"

        return prompt
    
    def _parse_response(self, response: str) -> List[ReviewIssue]:
        """ì‘ë‹µì—ì„œ ì´ìŠˆ íŒŒì‹±"""
        issues = []
        data = self._extract_json(response)

        if data:
            for item in data.get("issues", []):
                try:
                    issues.append(ReviewIssue(
                        file_path=item.get("file", "unknown"),
                        line_number=item.get("line"),
                        severity=Severity(item.get("severity", "medium")),
                        category=item.get("category", "suggestion"),
                        title=item.get("title", ""),
                        description=item.get("description", ""),
                        suggestion=item.get("suggestion"),
                        source="glm"
                    ))
                except (ValueError, KeyError) as e:
                    print(f"[WARN] Skipping invalid issue: {e}")

        return issues
    
    def _extract_json(self, response: str) -> Optional[dict]:
        """ì‘ë‹µì—ì„œ JSON ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
        # 1. JSON ì½”ë“œ ë¸”ë¡ ìš°ì„  ì‹œë„
        json_block = re.search(r'```json\s*(\{[\s\S]*?\})\s*```', response)
        if json_block:
            try:
                return json.loads(json_block.group(1))
            except json.JSONDecodeError:
                pass

        # 2. ì²« ë²ˆì§¸ ìœ íš¨í•œ JSON ê°ì²´ ì°¾ê¸° (balanced braces)
        start = response.find('{')
        if start == -1:
            return None

        depth = 0
        for i in range(start, len(response)):
            if response[i] == '{':
                depth += 1
            elif response[i] == '}':
                depth -= 1
                if depth == 0:
                    try:
                        return json.loads(response[start:i + 1])
                    except json.JSONDecodeError:
                        # ì´ JSONì´ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ë‹¤ìŒ ì‹œì‘ì  ì°¾ê¸°
                        start = response.find('{', i + 1)
                        if start == -1:
                            return None
                        depth = 0
                        continue
        return None

    def _extract_summary(self, response: str) -> str:
        """ì‘ë‹µì—ì„œ ìš”ì•½ ì¶”ì¶œ"""
        data = self._extract_json(response)
        if data:
            return data.get("summary", "")
        return ""


class GeminiReviewer:
    """Google Gemini 2.5 Flash ê¸°ë°˜ ì½”ë“œ ë¦¬ë·°ì–´"""
    
    def __init__(self, api_key: Optional[str] = None):
        self.api_key = api_key or os.environ.get("GEMINI_API_KEY") or os.environ.get("GOOGLE_API_KEY")
        self.model = None
        
        if self.api_key and GEMINI_AVAILABLE:
            genai.configure(api_key=self.api_key)
            self.model = genai.GenerativeModel('gemini-2.5-flash')
    
    @property
    def is_available(self) -> bool:
        return self.model is not None
    
    def review(self, diff: str, context: Dict[str, Any] = None) -> ReviewResult:
        """Geminië¡œ ì½”ë“œ ë¦¬ë·° ìˆ˜í–‰"""
        if not self.is_available:
            return ReviewResult(
                provider="gemini",
                success=False,
                error="Gemini API not configured"
            )
        
        try:
            prompt = self._build_prompt(diff, context)
            
            response = self.model.generate_content(
                prompt,
                generation_config=genai.GenerationConfig(
                    temperature=0.1,
                    max_output_tokens=4096
                )
            )
            
            raw_response = response.text

            # ë””ë²„ê¹…: raw response ì¶œë ¥
            print(f"[DEBUG] Gemini raw response length: {len(raw_response)} chars")
            if len(raw_response) < 500:
                print(f"[DEBUG] Full response: {raw_response}")
            else:
                print(f"[DEBUG] Response preview: {raw_response[:500]}...")

            issues = self._parse_response(raw_response)
            
            return ReviewResult(
                provider="gemini",
                success=True,
                issues=issues,
                summary=self._extract_summary(raw_response),
                raw_response=raw_response
            )
            
        except Exception as e:
            return ReviewResult(
                provider="gemini",
                success=False,
                error=str(e)
            )
    
    def _build_prompt(self, diff: str, context: Dict[str, Any] = None) -> str:
        system_context = """You are an expert code reviewer for FanPulse, a K-POP fan platform.

Tech Stack:
- Backend: Kotlin + Spring Boot 3.2 + PostgreSQL + MongoDB + Redis  
- Frontend: Next.js + TypeScript + TailwindCSS
- Mobile: Android (Jetpack Compose), iOS (UIKit/SwiftUI)

Review Guidelines:
1. Security vulnerabilities (SQL injection, XSS, auth bypass)
2. Bug detection and edge cases
3. Performance issues (N+1, memory leaks, inefficient algorithms)
4. Code quality and maintainability
5. Best practices for the tech stack

Output Format (JSON):
{
  "summary": "Brief overall assessment",
  "issues": [
    {
      "file": "path/to/file.kt",
      "line": 42,
      "severity": "critical|high|medium|low",
      "category": "security|bug|performance|style|suggestion",
      "title": "Short issue title",
      "description": "Detailed explanation",
      "suggestion": "How to fix (optional)"
    }
  ]
}

Be thorough but focus on significant issues. Avoid nitpicks."""
        
        MAX_DIFF_SIZE = 50000
        truncated = len(diff) > MAX_DIFF_SIZE

        if truncated:
            print(f"âš ï¸  Gemini: Diff truncated ({len(diff)} â†’ {MAX_DIFF_SIZE} chars)")
            diff_content = diff[:MAX_DIFF_SIZE] + "\n\n[... truncated, showing first 50KB ...]"
        else:
            diff_content = diff

        prompt = f"{system_context}\n\n---\n\nReview this code change:\n\n```diff\n{diff_content}\n```"

        if context:
            if context.get("pr_title"):
                prompt += f"\n\nPR Title: {context['pr_title']}"
            if context.get("pr_description"):
                prompt += f"\nPR Description: {context['pr_description']}"

        return prompt
    
    def _parse_response(self, response: str) -> List[ReviewIssue]:
        """ì‘ë‹µì—ì„œ ì´ìŠˆ íŒŒì‹±"""
        issues = []
        data = self._extract_json(response)

        if data:
            for item in data.get("issues", []):
                try:
                    issues.append(ReviewIssue(
                        file_path=item.get("file", "unknown"),
                        line_number=item.get("line"),
                        severity=Severity(item.get("severity", "medium")),
                        category=item.get("category", "suggestion"),
                        title=item.get("title", ""),
                        description=item.get("description", ""),
                        suggestion=item.get("suggestion"),
                        source="gemini"
                    ))
                except (ValueError, KeyError) as e:
                    print(f"âš ï¸  Skipping invalid issue: {e}")

        return issues

    def _extract_json(self, response: str) -> Optional[dict]:
        """ì‘ë‹µì—ì„œ JSON ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
        # 1. JSON ì½”ë“œ ë¸”ë¡ ìš°ì„  ì‹œë„
        json_block = re.search(r'```json\s*(\{[\s\S]*?\})\s*```', response)
        if json_block:
            try:
                return json.loads(json_block.group(1))
            except json.JSONDecodeError:
                pass

        # 2. ì²« ë²ˆì§¸ ìœ íš¨í•œ JSON ê°ì²´ ì°¾ê¸° (balanced braces)
        start = response.find('{')
        if start == -1:
            return None

        depth = 0
        for i in range(start, len(response)):
            if response[i] == '{':
                depth += 1
            elif response[i] == '}':
                depth -= 1
                if depth == 0:
                    try:
                        return json.loads(response[start:i + 1])
                    except json.JSONDecodeError:
                        start = response.find('{', i + 1)
                        if start == -1:
                            return None
                        depth = 0
                        continue
        return None

    def _extract_summary(self, response: str) -> str:
        """ì‘ë‹µì—ì„œ ìš”ì•½ ì¶”ì¶œ"""
        data = self._extract_json(response)
        if data:
            return data.get("summary", "")
        return ""


class HybridReviewer:
    """GLM + Gemini í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë·°ì–´"""

    def __init__(self, glm_key: str = None, gemini_key: str = None):
        self.glm = GLMReviewer(glm_key)
        self.gemini = GeminiReviewer(gemini_key)

    def review(self, diff: str, context: Dict[str, Any] = None, parallel: bool = True) -> MergedReview:
        """ë‘ AIë¡œ ë™ì‹œì— ë¦¬ë·°í•˜ê³  ê²°ê³¼ ë³‘í•©"""

        glm_result = None
        gemini_result = None

        if parallel and self.glm.is_available and self.gemini.is_available:
            # ë³‘ë ¬ ì‹¤í–‰
            with ThreadPoolExecutor(max_workers=2) as executor:
                futures = {
                    executor.submit(self.glm.review, diff, context): "glm",
                    executor.submit(self.gemini.review, diff, context): "gemini"
                }
                
                for future in as_completed(futures):
                    provider = futures[future]
                    try:
                        result = future.result(timeout=120)
                        if provider == "glm":
                            glm_result = result
                        else:
                            gemini_result = result
                    except Exception as e:
                        print(f"[WARN] {provider} failed: {e}")
        else:
            # ìˆœì°¨ ì‹¤í–‰
            if self.glm.is_available:
                print("Running GLM review...")
                glm_result = self.glm.review(diff, context)

            if self.gemini.is_available:
                print("Running Gemini review...")
                gemini_result = self.gemini.review(diff, context)
        
        # ê²°ê³¼ ë³‘í•©
        return self._merge_results(glm_result, gemini_result)

    def _merge_results(self, glm: Optional[ReviewResult], gemini: Optional[ReviewResult]) -> MergedReview:
        """ë‘ ë¦¬ë·° ê²°ê³¼ ë³‘í•©"""
        merged = MergedReview(
            glm_result=glm,
            gemini_result=gemini
        )

        all_issues: List[ReviewIssue] = []
        
        # ì´ìŠˆ ìˆ˜ì§‘
        if glm and glm.success:
            all_issues.extend(glm.issues)
        if gemini and gemini.success:
            all_issues.extend(gemini.issues)
        
        # ì¤‘ë³µ ì œê±° ë° í•©ì˜ ì‹ë³„
        seen = {}
        for issue in all_issues:
            key = f"{issue.file_path}:{issue.line_number}:{issue.category}"
            
            if key in seen:
                # ë‘ AIê°€ ê°™ì€ ì´ìŠˆ ì§€ì  = í•©ì˜
                existing = seen[key]
                if existing.source != issue.source:
                    # ì‹¬ê°ë„ëŠ” ë” ë†’ì€ ê²ƒ ì„ íƒ
                    severity_order = [Severity.CRITICAL, Severity.HIGH, Severity.MEDIUM, Severity.LOW, Severity.INFO]
                    if severity_order.index(issue.severity) < severity_order.index(existing.severity):
                        existing.severity = issue.severity
                    existing.source = "consensus"
                    merged.consensus_issues.append(existing)
            else:
                seen[key] = issue
        
        # ì •ë ¬: í•©ì˜ ì´ìŠˆ > Critical > High > Medium > Low
        merged.merged_issues = sorted(
            seen.values(),
            key=lambda x: (
                x.source != "consensus",
                [Severity.CRITICAL, Severity.HIGH, Severity.MEDIUM, Severity.LOW, Severity.INFO].index(x.severity)
            )
        )
        
        # í†µê³„
        merged.stats = {
            "total_issues": len(merged.merged_issues),
            "consensus_issues": len(merged.consensus_issues),
            "glm_only": len([i for i in merged.merged_issues if i.source == "glm"]),
            "gemini_only": len([i for i in merged.merged_issues if i.source == "gemini"]),
            "critical": len([i for i in merged.merged_issues if i.severity == Severity.CRITICAL]),
            "high": len([i for i in merged.merged_issues if i.severity == Severity.HIGH]),
            "medium": len([i for i in merged.merged_issues if i.severity == Severity.MEDIUM]),
            "low": len([i for i in merged.merged_issues if i.severity == Severity.LOW]),
        }
        
        # ìš”ì•½ ìƒì„±
        merged.summary = self._generate_summary(merged)
        
        return merged
    
    def _generate_summary(self, merged: MergedReview) -> str:
        """ë³‘í•©ëœ ë¦¬ë·° ìš”ì•½ ìƒì„±"""
        parts = []
        
        if merged.stats["critical"] > 0:
            parts.append(f"ğŸ”´ {merged.stats['critical']} critical issue(s)")
        if merged.stats["high"] > 0:
            parts.append(f"ğŸŸ  {merged.stats['high']} high priority issue(s)")
        if merged.stats["medium"] > 0:
            parts.append(f"ğŸŸ¡ {merged.stats['medium']} medium issue(s)")
        if merged.stats["low"] > 0:
            parts.append(f"ğŸŸ¢ {merged.stats['low']} suggestion(s)")
        
        if merged.stats["consensus_issues"] > 0:
            parts.append(f"âš ï¸ {merged.stats['consensus_issues']} issue(s) flagged by BOTH AI reviewers")
        
        if not parts:
            return "âœ… No significant issues found. LGTM!"

        return " | ".join(parts)


class ChunkedReviewer:
    """
    íŒŒì¼ë³„ ì²­í‚¹ì„ ì§€ì›í•˜ëŠ” ë¦¬ë·°ì–´

    í° diffë¥¼ íŒŒì¼ë³„ë¡œ ë‚˜ëˆ ì„œ ë³‘ë ¬ë¡œ ë¦¬ë·°í•˜ê³  ê²°ê³¼ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤.
    """

    # ì²­í‚¹ ì„ê³„ê°’ (ì´ í¬ê¸° ì´ìƒì´ë©´ íŒŒì¼ë³„ ë¶„ë¦¬)
    CHUNK_THRESHOLD = 40000  # 40KB
    MAX_CHUNK_SIZE = 30000   # ê° ì²­í¬ ìµœëŒ€ 30KB
    MAX_PARALLEL_CHUNKS = 5  # ë™ì‹œ ë¦¬ë·° ìµœëŒ€ ì²­í¬ ìˆ˜

    def __init__(self, glm_key: str = None, gemini_key: str = None):
        self.hybrid = HybridReviewer(glm_key, gemini_key)
        self.glm = self.hybrid.glm
        self.gemini = self.hybrid.gemini

    def review(
        self,
        diff: str,
        context: Dict[str, Any] = None,
        use_glm: bool = True,
        use_gemini: bool = True
    ) -> MergedReview:
        """
        ìŠ¤ë§ˆíŠ¸ ë¦¬ë·°: í¬ê¸°ì— ë”°ë¼ ì¼ë°˜/ì²­í‚¹ ë°©ì‹ ì„ íƒ

        Args:
            diff: Git diff ë‚´ìš©
            context: PR ì •ë³´ (title, description ë“±)
            use_glm: GLM ì‚¬ìš© ì—¬ë¶€
            use_gemini: Gemini ì‚¬ìš© ì—¬ë¶€
        """
        diff_size = len(diff)

        # ì‘ì€ diffëŠ” ì¼ë°˜ ë¦¬ë·°
        if diff_size < self.CHUNK_THRESHOLD:
            print(f"ğŸ“ ì¼ë°˜ ë¦¬ë·° ëª¨ë“œ (diff: {diff_size:,} chars)")
            return self._single_review(diff, context, use_glm, use_gemini)

        # í° diffëŠ” ì²­í‚¹ ë¦¬ë·°
        print(f"ğŸ“¦ ì²­í‚¹ ë¦¬ë·° ëª¨ë“œ (diff: {diff_size:,} chars, threshold: {self.CHUNK_THRESHOLD:,})")
        return self._chunked_review(diff, context, use_glm, use_gemini)

    def _single_review(
        self,
        diff: str,
        context: Dict[str, Any],
        use_glm: bool,
        use_gemini: bool
    ) -> MergedReview:
        """ì¼ë°˜ ë¦¬ë·° (ì²­í‚¹ ì—†ìŒ)"""
        if use_glm and use_gemini:
            return self.hybrid.review(diff, context)
        elif use_glm:
            result = self.glm.review(diff, context)
            return self._wrap_single_result(result, "glm")
        elif use_gemini:
            result = self.gemini.review(diff, context)
            return self._wrap_single_result(result, "gemini")
        else:
            return MergedReview(glm_result=None, gemini_result=None)

    def _chunked_review(
        self,
        diff: str,
        context: Dict[str, Any],
        use_glm: bool,
        use_gemini: bool
    ) -> MergedReview:
        """íŒŒì¼ë³„ ì²­í‚¹ ë¦¬ë·°"""
        # 1. íŒŒì¼ë³„ë¡œ diff ë¶„ë¦¬
        chunks = parse_diff_by_files(diff)
        code_chunks = [c for c in chunks if c.is_code_file]

        print(f"   ğŸ“ ì´ {len(chunks)}ê°œ íŒŒì¼ ì¤‘ {len(code_chunks)}ê°œ ì½”ë“œ íŒŒì¼ ë°œê²¬")

        if not code_chunks:
            print("   âš ï¸ ë¦¬ë·°í•  ì½”ë“œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
            return MergedReview(
                glm_result=None,
                gemini_result=None,
                summary="No code files to review"
            )

        # 2. í¬ê¸° ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”
        groups = group_chunks_by_size(code_chunks, self.MAX_CHUNK_SIZE)
        print(f"   ğŸ“¦ {len(groups)}ê°œ ê·¸ë£¹ìœ¼ë¡œ ë¶„í• ")

        # 3. ê° ê·¸ë£¹ë³„ ë³‘ë ¬ ë¦¬ë·°
        all_issues: List[ReviewIssue] = []

        # ë™ì‹œ ì‹¤í–‰ ì œí•œ
        groups_to_review = groups[:self.MAX_PARALLEL_CHUNKS]
        if len(groups) > self.MAX_PARALLEL_CHUNKS:
            print(f"   âš ï¸ {len(groups) - self.MAX_PARALLEL_CHUNKS}ê°œ ê·¸ë£¹ ìŠ¤í‚µ (ìµœëŒ€ {self.MAX_PARALLEL_CHUNKS}ê°œ)")

        with ThreadPoolExecutor(max_workers=self.MAX_PARALLEL_CHUNKS) as executor:
            futures = {}

            for i, group in enumerate(groups_to_review):
                group_diff = merge_chunks_to_diff(group)
                file_names = [c.file_path for c in group]

                print(f"   ğŸ” ê·¸ë£¹ {i+1}: {len(group)}ê°œ íŒŒì¼ ({len(group_diff):,} chars)")
                for name in file_names[:3]:  # ìµœëŒ€ 3ê°œë§Œ ì¶œë ¥
                    print(f"      - {name}")
                if len(file_names) > 3:
                    print(f"      ... ì™¸ {len(file_names) - 3}ê°œ")

                # ë¦¬ë·° ì œì¶œ
                future = executor.submit(
                    self._review_chunk,
                    group_diff,
                    context,
                    use_glm,
                    use_gemini
                )
                futures[future] = i

            # ê²°ê³¼ ìˆ˜ì§‘
            for future in as_completed(futures):
                group_idx = futures[future]
                try:
                    result = future.result(timeout=180)  # 3ë¶„ íƒ€ì„ì•„ì›ƒ
                    issues = result.merged_issues if hasattr(result, 'merged_issues') else []
                    all_issues.extend(issues)
                    print(f"   âœ… ê·¸ë£¹ {group_idx + 1} ì™„ë£Œ: {len(issues)}ê°œ ì´ìŠˆ")
                except Exception as e:
                    print(f"   âŒ ê·¸ë£¹ {group_idx + 1} ì‹¤íŒ¨: {e}")

        # 4. ê²°ê³¼ ë³‘í•©
        return self._merge_chunked_results(all_issues, use_glm, use_gemini)

    def _review_chunk(
        self,
        diff: str,
        context: Dict[str, Any],
        use_glm: bool,
        use_gemini: bool
    ) -> MergedReview:
        """ë‹¨ì¼ ì²­í¬ ë¦¬ë·°"""
        return self._single_review(diff, context, use_glm, use_gemini)

    def _wrap_single_result(self, result: ReviewResult, provider: str) -> MergedReview:
        """ë‹¨ì¼ ë¦¬ë·° ê²°ê³¼ë¥¼ MergedReviewë¡œ ë˜í•‘"""
        merged = MergedReview(
            glm_result=result if provider == "glm" else None,
            gemini_result=result if provider == "gemini" else None
        )
        merged.merged_issues = result.issues if result.success else []
        merged.summary = result.summary if result.success else (result.error or "Review failed")
        merged.stats = {
            "total_issues": len(merged.merged_issues),
            "consensus_issues": 0,
            "glm_only": len(merged.merged_issues) if provider == "glm" else 0,
            "gemini_only": len(merged.merged_issues) if provider == "gemini" else 0,
            "critical": len([i for i in merged.merged_issues if i.severity == Severity.CRITICAL]),
            "high": len([i for i in merged.merged_issues if i.severity == Severity.HIGH]),
            "medium": len([i for i in merged.merged_issues if i.severity == Severity.MEDIUM]),
            "low": len([i for i in merged.merged_issues if i.severity == Severity.LOW]),
        }
        return merged

    def _merge_chunked_results(
        self,
        all_issues: List[ReviewIssue],
        use_glm: bool,
        use_gemini: bool
    ) -> MergedReview:
        """ì²­í‚¹ëœ ëª¨ë“  ê²°ê³¼ ë³‘í•©"""
        # ì¤‘ë³µ ì œê±° (ê°™ì€ íŒŒì¼, ê°™ì€ ë¼ì¸, ê°™ì€ ì¹´í…Œê³ ë¦¬)
        seen = {}
        for issue in all_issues:
            key = f"{issue.file_path}:{issue.line_number}:{issue.category}:{issue.title[:30]}"
            if key not in seen:
                seen[key] = issue

        unique_issues = list(seen.values())

        # ì‹¬ê°ë„ìˆœ ì •ë ¬
        severity_order = [Severity.CRITICAL, Severity.HIGH, Severity.MEDIUM, Severity.LOW, Severity.INFO]
        sorted_issues = sorted(
            unique_issues,
            key=lambda x: severity_order.index(x.severity)
        )

        merged = MergedReview(glm_result=None, gemini_result=None)
        merged.merged_issues = sorted_issues
        merged.stats = {
            "total_issues": len(sorted_issues),
            "consensus_issues": len([i for i in sorted_issues if i.source == "consensus"]),
            "glm_only": len([i for i in sorted_issues if i.source == "glm"]),
            "gemini_only": len([i for i in sorted_issues if i.source == "gemini"]),
            "critical": len([i for i in sorted_issues if i.severity == Severity.CRITICAL]),
            "high": len([i for i in sorted_issues if i.severity == Severity.HIGH]),
            "medium": len([i for i in sorted_issues if i.severity == Severity.MEDIUM]),
            "low": len([i for i in sorted_issues if i.severity == Severity.LOW]),
        }

        # ìš”ì•½ ìƒì„±
        parts = []
        if merged.stats["critical"] > 0:
            parts.append(f"ğŸ”´ {merged.stats['critical']} critical")
        if merged.stats["high"] > 0:
            parts.append(f"ğŸŸ  {merged.stats['high']} high")
        if merged.stats["medium"] > 0:
            parts.append(f"ğŸŸ¡ {merged.stats['medium']} medium")
        if merged.stats["low"] > 0:
            parts.append(f"ğŸŸ¢ {merged.stats['low']} low")

        merged.summary = " | ".join(parts) if parts else "âœ… No significant issues found. LGTM!"

        return merged


def format_review_markdown(merged: MergedReview) -> str:
    """ë¦¬ë·° ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í¬ë§·"""
    lines = [
        "# ğŸ¤– AI Code Review Results",
        "",
        f"**Reviewers:** GLM-4-Flash + Gemini 2.5 Flash (Hybrid)",
        "",
        f"## Summary",
        f"{merged.summary}",
        "",
    ]
    
    # í†µê³„
    lines.extend([
        "### ğŸ“Š Statistics",
        f"- Total Issues: {merged.stats['total_issues']}",
        f"- Consensus (Both AIs agree): {merged.stats['consensus_issues']}",
        f"- GLM only: {merged.stats['glm_only']}",
        f"- Gemini only: {merged.stats['gemini_only']}",
        "",
    ])
    
    # í•©ì˜ëœ ì´ìŠˆ (ê°€ì¥ ì¤‘ìš”)
    if merged.consensus_issues:
        lines.extend([
            "## âš ï¸ Consensus Issues (Both AIs Flagged)",
            "_These issues were identified by both AI reviewers and should be prioritized._",
            "",
        ])
        for issue in merged.consensus_issues:
            lines.extend(format_issue_markdown(issue))
    
    # Critical ì´ìŠˆ
    critical = [i for i in merged.merged_issues if i.severity == Severity.CRITICAL and i.source != "consensus"]
    if critical:
        lines.extend([
            "## ğŸ”´ Critical Issues",
            "",
        ])
        for issue in critical:
            lines.extend(format_issue_markdown(issue))
    
    # High ì´ìŠˆ
    high = [i for i in merged.merged_issues if i.severity == Severity.HIGH and i.source != "consensus"]
    if high:
        lines.extend([
            "## ğŸŸ  High Priority",
            "",
        ])
        for issue in high:
            lines.extend(format_issue_markdown(issue))
    
    # Medium ì´ìŠˆ
    medium = [i for i in merged.merged_issues if i.severity == Severity.MEDIUM and i.source != "consensus"]
    if medium:
        lines.extend([
            "## ğŸŸ¡ Medium Priority",
            "",
        ])
        for issue in medium:
            lines.extend(format_issue_markdown(issue))
    
    # Low/Suggestions
    low = [i for i in merged.merged_issues if i.severity in [Severity.LOW, Severity.INFO] and i.source != "consensus"]
    if low:
        lines.extend([
            "## ğŸŸ¢ Suggestions",
            "",
        ])
        for issue in low:
            lines.extend(format_issue_markdown(issue))
    
    # Footer
    lines.extend([
        "",
        "---",
        "_Powered by GLM-4-Flash (Zhipu AI) + Gemini 2.5 Flash_",
        "_Issues flagged by both AIs have higher confidence._",
    ])
    
    return "\n".join(lines)


def format_issue_markdown(issue: ReviewIssue) -> List[str]:
    """ê°œë³„ ì´ìŠˆë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í¬ë§·"""
    source_badge = {
        "glm": "ğŸ¤– GLM",
        "gemini": "âœ¨ Gemini",
        "consensus": "ğŸ”¥ Consensus"
    }.get(issue.source, issue.source)
    
    location = f"`{issue.file_path}`"
    if issue.line_number:
        location += f" (line {issue.line_number})"
    
    lines = [
        f"### {issue.title}",
        f"**Location:** {location}",
        f"**Category:** {issue.category} | **Source:** {source_badge}",
        "",
        issue.description,
        "",
    ]
    
    if issue.suggestion:
        lines.extend([
            "**Suggestion:**",
            f"> {issue.suggestion}",
            "",
        ])
    
    return lines


def get_pr_diff(pr_number: int) -> Tuple[str, Dict[str, Any]]:
    """GitHub PRì˜ diffì™€ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
    try:
        # PR ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        result = subprocess.run(
            ["gh", "pr", "view", str(pr_number), "--json", "title,body,files"],
            capture_output=True,
            text=True,
            timeout=30
        )
        
        context = {}
        if result.returncode == 0:
            data = json.loads(result.stdout)
            context = {
                "pr_title": data.get("title", ""),
                "pr_description": data.get("body", ""),
            }
        
        # Diff ê°€ì ¸ì˜¤ê¸°
        diff_result = subprocess.run(
            ["gh", "pr", "diff", str(pr_number)],
            capture_output=True,
            text=True,
            timeout=60
        )
        
        return diff_result.stdout, context
        
    except Exception as e:
        print(f"âš ï¸  Error fetching PR: {e}")
        return "", {}


def post_review_comment(pr_number: int, body: str) -> bool:
    """PRì— ë¦¬ë·° ì½”ë©˜íŠ¸ ê²Œì‹œ"""
    try:
        result = subprocess.run(
            ["gh", "pr", "comment", str(pr_number), "--body", body],
            capture_output=True,
            text=True,
            timeout=30
        )
        return result.returncode == 0
    except Exception as e:
        print(f"âš ï¸  Error posting comment: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description="AI PR Code Reviewer (GLM + Gemini Hybrid)")
    parser.add_argument("--pr", type=int, help="GitHub PR number to review")
    parser.add_argument("--diff", type=str, help="Direct diff content to review")
    parser.add_argument("--diff-file", type=str, help="File containing diff to review")
    parser.add_argument("--output", "-o", type=str, help="Output file for review (markdown)")
    parser.add_argument("--json", type=str, help="Output file for raw JSON results")
    parser.add_argument("--post-comment", action="store_true", help="Post review as PR comment")
    parser.add_argument("--glm-only", action="store_true", help="Use only GLM")
    parser.add_argument("--gemini-only", action="store_true", help="Use only Gemini")
    parser.add_argument("--no-chunk", action="store_true", help="Disable file chunking for large diffs")
    parser.add_argument("--chunk-threshold", type=int, default=40000,
                       help="Diff size threshold for chunking (default: 40000 chars)")

    args = parser.parse_args()
    
    # Diff ê°€ì ¸ì˜¤ê¸°
    diff = ""
    context = {}
    
    if args.pr:
        print(f"ğŸ“¥ Fetching PR #{args.pr}...")
        diff, context = get_pr_diff(args.pr)
    elif args.diff:
        diff = args.diff
    elif args.diff_file:
        diff = Path(args.diff_file).read_text(encoding='utf-8')
    else:
        # stdinì—ì„œ ì½ê¸°
        print("ğŸ“¥ Reading diff from stdin...")
        import sys
        diff = sys.stdin.read()
    
    if not diff.strip():
        print("âŒ No diff content provided")
        return 1
    
    print(f"ğŸ“ Diff size: {len(diff):,} chars")

    # ë¦¬ë·°ì–´ ì´ˆê¸°í™” (ì²­í‚¹ ì§€ì›)
    reviewer = ChunkedReviewer()

    # ì²­í‚¹ ì„¤ì • ì ìš©
    if args.no_chunk:
        reviewer.CHUNK_THRESHOLD = float('inf')  # ì²­í‚¹ ë¹„í™œì„±í™”
        print("âš ï¸ ì²­í‚¹ ë¹„í™œì„±í™”ë¨ (--no-chunk)")
    else:
        reviewer.CHUNK_THRESHOLD = args.chunk_threshold

    # ì‚¬ìš©í•  AI ê²°ì •
    use_glm = not args.gemini_only
    use_gemini = not args.glm_only

    # API ê°€ìš©ì„± ì²´í¬
    if use_glm and not reviewer.glm.is_available:
        if args.glm_only:
            print("âŒ GLM API not configured (GLM_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”)")
            return 1
        use_glm = False

    if use_gemini and not reviewer.gemini.is_available:
        if args.gemini_only:
            print("âŒ Gemini API not configured (GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”)")
            return 1
        use_gemini = False

    if not use_glm and not use_gemini:
        print("âŒ No AI providers configured. Set GLM_API_KEY or GEMINI_API_KEY")
        return 1

    # ì‚¬ìš©í•  AI í‘œì‹œ
    providers = []
    if use_glm:
        providers.append("GLM-4-Flash")
    if use_gemini:
        providers.append("Gemini 2.5 Flash")
    print(f"ğŸ” AI Reviewers: {', '.join(providers)}")

    # ë¦¬ë·° ì‹¤í–‰ (ìë™ ì²­í‚¹)
    merged = reviewer.review(diff, context, use_glm=use_glm, use_gemini=use_gemini)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print(merged.summary)
    print("="*60 + "\n")
    
    # ë§ˆí¬ë‹¤ìš´ ìƒì„±
    markdown = format_review_markdown(merged)
    
    # íŒŒì¼ ì¶œë ¥
    if args.output:
        Path(args.output).write_text(markdown)
        print(f"ğŸ“„ Review saved to: {args.output}")
    
    if args.json:
        json_data = {
            "summary": merged.summary,
            "stats": merged.stats,
            "issues": [asdict(i) for i in merged.merged_issues],
            "consensus_issues": [asdict(i) for i in merged.consensus_issues],
        }
        # Enum ì§ë ¬í™”
        for issue in json_data["issues"] + json_data["consensus_issues"]:
            issue["severity"] = issue["severity"].value if isinstance(issue["severity"], Severity) else issue["severity"]
        
        Path(args.json).write_text(json.dumps(json_data, indent=2, ensure_ascii=False))
        print(f"ğŸ“„ JSON saved to: {args.json}")
    
    # PR ì½”ë©˜íŠ¸ ê²Œì‹œ
    if args.post_comment and args.pr:
        print(f"ğŸ’¬ Posting comment to PR #{args.pr}...")
        if post_review_comment(args.pr, markdown):
            print("âœ… Comment posted successfully")
        else:
            print("âŒ Failed to post comment")
    
    # ê¸°ë³¸ ì¶œë ¥
    if not args.output and not args.json:
        print(markdown)
    
    # Exit code: critical ì´ìŠˆê°€ ìˆìœ¼ë©´ 1
    if merged.stats.get("critical", 0) > 0:
        return 1
    return 0


if __name__ == "__main__":
    exit(main())
