diff --git a/.claude/agents/ai-pr-reviewer.md b/.claude/agents/ai-pr-reviewer.md
new file mode 100644
index 0000000..559acb0
--- /dev/null
+++ b/.claude/agents/ai-pr-reviewer.md
@@ -0,0 +1,122 @@
+---
+name: ai-pr-reviewer
+description: |
+  AI PR ì½”ë“œ ë¦¬ë·° ì—ì´ì „íŠ¸. GLM-4-Flashì™€ Gemini 2.5 Flashë¥¼ ë™ì‹œì— ì‚¬ìš©í•˜ì—¬
+  PRì˜ ì½”ë“œë¥¼ ë¶„ì„í•˜ê³  ë²„ê·¸, ë³´ì•ˆ ì·¨ì•½ì , ì„±ëŠ¥ ì´ìŠˆë¥¼ ì°¾ì•„ëƒ…ë‹ˆë‹¤.
+  ì‚¬ìš© ì‹œê¸°: (1) PR ìƒì„± ì‹œ (2) ì½”ë“œ ë¦¬ë·° ìš”ì²­ ì‹œ (3) ë¨¸ì§€ ì „ ìµœì¢… ê²€í†  ì‹œ
+tools: Read, Grep, Glob, Bash
+model: sonnet
+---
+
+# AI PR Code Reviewer Agent
+
+GLM-4-Flash (Zhipu AI) + Gemini 2.5 Flash í•˜ì´ë¸Œë¦¬ë“œ ì½”ë“œ ë¦¬ë·°ì–´.
+
+## When to Use
+
+- PRì´ ìƒì„±ë˜ì—ˆì„ ë•Œ ìë™ ë¦¬ë·°
+- ìˆ˜ë™ìœ¼ë¡œ ì½”ë“œ ë¦¬ë·° ìš”ì²­ ì‹œ
+- ë¨¸ì§€ ì „ ìµœì¢… í’ˆì§ˆ ê²€í† 
+
+## Quick Start
+
+```bash
+# PR ë²ˆí˜¸ë¡œ ë¦¬ë·°
+python script/ai_pr_reviewer.py --pr 123
+
+# ë¡œì»¬ diff ë¦¬ë·°
+git diff main | python script/ai_pr_reviewer.py
+
+# ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
+python script/ai_pr_reviewer.py --pr 123 --output review.md --json review.json
+
+# Geminië§Œ ì‚¬ìš©
+python script/ai_pr_reviewer.py --pr 123 --gemini-only
+
+# GLMë§Œ ì‚¬ìš©
+python script/ai_pr_reviewer.py --pr 123 --glm-only
+```
+
+## Execution Flow
+
+1. **Pre-analysis**: ê¸°ì¡´ `pr_analyzer.py`ë¡œ íŒŒì¼ë³„ ë¦¬ìŠ¤í¬ í‰ê°€
+2. **AI Review**: GLM + Gemini ë³‘ë ¬ ì‹¤í–‰
+3. **Merge Results**: ë‘ AI ê²°ê³¼ ë³‘í•©, í•©ì˜ ì´ìŠˆ ì‹ë³„
+4. **Report**: ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±
+
+## Integration with pr_analyzer.py
+
+```bash
+# 1ë‹¨ê³„: ì •ì  ë¶„ì„ìœ¼ë¡œ ìš°ì„ ìˆœìœ„ íŒŒì•…
+python script/pr_analyzer.py --pr 123 --output .claude/pr-analysis.json
+
+# 2ë‹¨ê³„: AI ë¦¬ë·° (ê³ ìœ„í—˜ íŒŒì¼ ì§‘ì¤‘)
+python script/ai_pr_reviewer.py --pr 123 --output .claude/ai-review.md
+```
+
+## Environment Variables
+
+| Variable | Required | Description |
+|----------|----------|-------------|
+| `GLM_API_KEY` | One of these | Zhipu AI GLM API í‚¤ |
+| `GEMINI_API_KEY` | One of these | Google Gemini API í‚¤ |
+| `GITHUB_TOKEN` | For PR access | GitHub API í† í° |
+
+## Output Format
+
+### Severity Levels
+
+- ğŸ”´ **Critical**: ë³´ì•ˆ ì·¨ì•½ì , í¬ë˜ì‹œ ë²„ê·¸, ë°ì´í„° ì†ì‹¤
+- ğŸŸ  **High**: ì„±ëŠ¥ ë¬¸ì œ, ì•„í‚¤í…ì²˜ ì´ìŠˆ, ì¤‘ìš” ë¡œì§ ì˜¤ë¥˜
+- ğŸŸ¡ **Medium**: ì½”ë“œ ìŠ¤íƒ€ì¼, ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ìœ„ë°˜
+- ğŸŸ¢ **Low**: ì œì•ˆ, ê°œì„ ì‚¬í•­, ë¦¬íŒ©í† ë§ ì•„ì´ë””ì–´
+
+### Consensus Issues (âš ï¸ ì¤‘ìš”!)
+
+ë‘ AIê°€ ë™ì‹œì— ì§€ì í•œ ì´ìŠˆëŠ” **Consensus**ë¡œ í‘œì‹œë©ë‹ˆë‹¤.
+ì´ëŸ¬í•œ ì´ìŠˆëŠ” ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§€ë©° ë°˜ë“œì‹œ ê²€í† í•´ì•¼ í•©ë‹ˆë‹¤.
+
+## GitHub Actions Integration
+
+PR ìƒì„± ì‹œ ìë™ìœ¼ë¡œ ë¦¬ë·°ê°€ ì‹¤í–‰ë©ë‹ˆë‹¤:
+- `.github/workflows/ai-code-review.yml` ì›Œí¬í”Œë¡œìš°
+- PRì— ì½”ë©˜íŠ¸ë¡œ ë¦¬ë·° ê²°ê³¼ ê²Œì‹œ
+- Critical ì´ìŠˆ ë°œê²¬ ì‹œ ê²½ê³  í‘œì‹œ
+
+## Customization
+
+### Tech Stack ìˆ˜ì •
+
+`script/ai_pr_reviewer.py`ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì—ì„œ ìˆ˜ì •:
+
+```python
+Tech Stack:
+- Backend: Kotlin + Spring Boot 3.2 + PostgreSQL + MongoDB + Redis
+- Frontend: Next.js + TypeScript + TailwindCSS
+- Mobile: Android (Jetpack Compose), iOS (UIKit/SwiftUI)
+```
+
+### ë¦¬ë·° ê·œì¹™ ì¶”ê°€
+
+`.claude/rules/` ë””ë ‰í† ë¦¬ì˜ ê·œì¹™ íŒŒì¼ì„ ì°¸ì¡°í•˜ë„ë¡ ìˆ˜ì • ê°€ëŠ¥.
+
+## Troubleshooting
+
+### API í‚¤ ì˜¤ë¥˜
+```bash
+# Linux/macOS
+echo $GLM_API_KEY
+echo $GEMINI_API_KEY
+
+# PowerShell (Windows)
+echo $env:GLM_API_KEY
+echo $env:GEMINI_API_KEY
+```
+
+### Rate Limit
+- GLM: ê°€ì… ì‹œ ë¬´ë£Œ í¬ë ˆë”§ ì œê³µ
+- Gemini: 15 req/min (ë¬´ë£Œ í‹°ì–´)
+
+### í° PR ì²˜ë¦¬
+- Diffê°€ 50K ì´ìƒì´ë©´ ìë™ìœ¼ë¡œ ì˜ë¦¼
+- ê³ ìœ„í—˜ íŒŒì¼ë§Œ ì„ ë³„í•˜ì—¬ ë¦¬ë·°í•˜ëŠ” ê²ƒì„ ê¶Œì¥
diff --git a/.github/workflows/ai-code-review.yml b/.github/workflows/ai-code-review.yml
new file mode 100644
index 0000000..7f19ebf
--- /dev/null
+++ b/.github/workflows/ai-code-review.yml
@@ -0,0 +1,188 @@
+name: AI Code Review (GLM + Gemini)
+
+on:
+  pull_request:
+    types: [opened, synchronize, reopened]
+    # íŠ¹ì • ë¸Œëœì¹˜ë§Œ ë¦¬ë·° (ì„ íƒì‚¬í•­)
+    # branches:
+    #   - main
+    #   - develop
+
+# ë™ì‹œ ì‹¤í–‰ ë°©ì§€ - ê°™ì€ PRì˜ ì´ì „ ë¦¬ë·° ì·¨ì†Œ
+concurrency:
+  group: ai-review-${{ github.event.pull_request.number }}
+  cancel-in-progress: true
+
+permissions:
+  contents: read
+  pull-requests: write
+
+jobs:
+  # ë¨¼ì € ë¦¬ë·° ëŒ€ìƒ íŒŒì¼ì¸ì§€ í™•ì¸
+  check-files:
+    name: Check Changed Files
+    runs-on: ubuntu-latest
+    outputs:
+      should_review: ${{ steps.check.outputs.should_review }}
+    steps:
+      - name: Check for reviewable files
+        id: check
+        env:
+          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+        run: |
+          # ë³€ê²½ëœ íŒŒì¼ ëª©ë¡
+          FILES=$(gh pr view ${{ github.event.pull_request.number }} --json files --jq '.files[].path')
+
+          # ë¦¬ë·° ëŒ€ìƒ íŒŒì¼ íŒ¨í„´
+          REVIEW_PATTERNS="\.kt$|\.java$|\.py$|\.ts$|\.tsx$|\.js$|\.jsx$|\.swift$"
+
+          # íŒ¨í„´ ë§¤ì¹­
+          if echo "$FILES" | grep -qE "$REVIEW_PATTERNS"; then
+            echo "should_review=true" >> $GITHUB_OUTPUT
+            echo "Found reviewable code files"
+          else
+            echo "should_review=false" >> $GITHUB_OUTPUT
+            echo "No code files to review (only config/docs changed)"
+          fi
+
+  ai-code-review:
+    name: AI Code Review
+    runs-on: ubuntu-latest
+    needs: check-files
+    # Draft PR ìŠ¤í‚µ + ì½”ë“œ íŒŒì¼ ë³€ê²½ ì‹œì—ë§Œ ì‹¤í–‰
+    if: |
+      github.event.pull_request.draft == false &&
+      needs.check-files.outputs.should_review == 'true'
+
+    steps:
+      - name: Checkout repository
+        uses: actions/checkout@v4
+        with:
+          fetch-depth: 0  # ì „ì²´ íˆìŠ¤í† ë¦¬ (diff ê³„ì‚°ìš©)
+
+      - name: Setup Python
+        uses: actions/setup-python@v5
+        with:
+          python-version: '3.11'
+          cache: 'pip'
+
+      - name: Install dependencies
+        run: |
+          pip install --upgrade pip
+          pip install google-generativeai openai requests
+
+      - name: Get PR diff
+        id: diff
+        env:
+          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+        run: |
+          # PR diff ê°€ì ¸ì˜¤ê¸°
+          gh pr diff ${{ github.event.pull_request.number }} > pr_diff.txt
+
+          # Diff í¬ê¸° í™•ì¸
+          DIFF_SIZE=$(wc -c < pr_diff.txt)
+          echo "diff_size=$DIFF_SIZE" >> $GITHUB_OUTPUT
+
+          # ë„ˆë¬´ í¬ë©´ ìŠ¤í‚µ
+          if [ $DIFF_SIZE -gt 200000 ]; then
+            echo "::warning::Diff too large for AI review ($DIFF_SIZE bytes)"
+            echo "large_diff=skip" >> $GITHUB_OUTPUT
+            gh pr comment ${{ github.event.pull_request.number }} --body "AI Code Review: PR diffê°€ ë„ˆë¬´ í½ë‹ˆë‹¤ (200KB ì´ˆê³¼). ì‘ì€ PRë¡œ ë‚˜ëˆ ì£¼ì„¸ìš”."
+          elif [ $DIFF_SIZE -gt 100000 ]; then
+            echo "::warning::Large diff detected: $DIFF_SIZE bytes"
+            echo "large_diff=true" >> $GITHUB_OUTPUT
+          else
+            echo "large_diff=false" >> $GITHUB_OUTPUT
+          fi
+
+      - name: Run AI Code Review
+        id: review
+        if: steps.diff.outputs.large_diff != 'skip'
+        env:
+          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
+          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+        run: |
+          # Geminië§Œ ì‚¬ìš©í•˜ì—¬ ë¦¬ë·° ì‹¤í–‰
+          python script/ai_pr_reviewer.py \
+            --diff-file pr_diff.txt \
+            --output review_result.md \
+            --json review_result.json \
+            --gemini-only
+
+          # ê²°ê³¼ í™•ì¸ (JSON ê²€ì¦ í¬í•¨)
+          if [ -f review_result.json ]; then
+            # JSON ìœ íš¨ì„± ê²€ì‚¬
+            if ! jq empty review_result.json 2>/dev/null; then
+              echo "::warning::Invalid JSON in review result"
+              echo "critical=0" >> $GITHUB_OUTPUT
+              echo "high=0" >> $GITHUB_OUTPUT
+              echo "total=0" >> $GITHUB_OUTPUT
+            else
+              CRITICAL=$(jq -r '.stats.critical // 0' review_result.json)
+              HIGH=$(jq -r '.stats.high // 0' review_result.json)
+              TOTAL=$(jq -r '.stats.total_issues // 0' review_result.json)
+
+              echo "critical=$CRITICAL" >> $GITHUB_OUTPUT
+              echo "high=$HIGH" >> $GITHUB_OUTPUT
+              echo "total=$TOTAL" >> $GITHUB_OUTPUT
+            fi
+          else
+            echo "::warning::Review result file not found"
+            echo "critical=0" >> $GITHUB_OUTPUT
+            echo "high=0" >> $GITHUB_OUTPUT
+            echo "total=0" >> $GITHUB_OUTPUT
+          fi
+
+      - name: Post review comment
+        if: always()
+        env:
+          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+        run: |
+          if [ -f review_result.md ]; then
+            # ê¸°ì¡´ AI ë¦¬ë·° ì½”ë©˜íŠ¸ ì°¾ì•„ì„œ ì‚­ì œ (ì—…ë°ì´íŠ¸ìš©)
+            EXISTING_COMMENT=$(gh pr view ${{ github.event.pull_request.number }} \
+              --json comments \
+              --jq '.comments[] | select(.body | contains("AI Code Review Results")) | .id' \
+              | head -1)
+
+            if [ -n "$EXISTING_COMMENT" ]; then
+              echo "Updating existing review comment..."
+              gh api -X DELETE "/repos/${{ github.repository }}/issues/comments/$EXISTING_COMMENT" || true
+            fi
+
+            # ìƒˆ ì½”ë©˜íŠ¸ ê²Œì‹œ
+            gh pr comment ${{ github.event.pull_request.number }} --body-file review_result.md
+            echo "âœ… Review comment posted"
+          else
+            echo "âš ï¸ No review result file found"
+            gh pr comment ${{ github.event.pull_request.number }} --body "âš ï¸ AI Code Review failed to generate results. Check the workflow logs for details."
+          fi
+
+      - name: Upload review artifacts
+        if: always()
+        uses: actions/upload-artifact@v4
+        with:
+          name: ai-review-results
+          path: |
+            review_result.md
+            review_result.json
+            pr_diff.txt
+          retention-days: 7
+
+      - name: Set review status
+        if: always()
+        env:
+          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
+        run: |
+          CRITICAL=${{ steps.review.outputs.critical || 0 }}
+          HIGH=${{ steps.review.outputs.high || 0 }}
+
+          if [ "$CRITICAL" -gt 0 ]; then
+            echo "::error::Found $CRITICAL critical issue(s). Please review before merging."
+            # ì„ íƒ: critical ì´ìŠˆê°€ ìˆìœ¼ë©´ ì‹¤íŒ¨ë¡œ í‘œì‹œ
+            # exit 1
+          elif [ "$HIGH" -gt 0 ]; then
+            echo "::warning::Found $HIGH high priority issue(s). Consider addressing them."
+          else
+            echo "No critical issues found"
+          fi
diff --git a/doc/ai-code-review-setup.md b/doc/ai-code-review-setup.md
new file mode 100644
index 0000000..1994681
--- /dev/null
+++ b/doc/ai-code-review-setup.md
@@ -0,0 +1,240 @@
+# AI ì½”ë“œ ë¦¬ë·° ë´‡ ì„¤ì • ê°€ì´ë“œ
+
+FanPulse í”„ë¡œì íŠ¸ë¥¼ ìœ„í•œ AI ì½”ë“œ ë¦¬ë·° ë´‡ (GLM + Gemini í•˜ì´ë¸Œë¦¬ë“œ) ì„¤ì • ê°€ì´ë“œì…ë‹ˆë‹¤.
+
+## ğŸ“‹ ê°œìš”
+
+ì´ ë´‡ì€ **GLM-4-Flash**ì™€ **Gemini 2.5 Flash**ë¥¼ ë™ì‹œì— ì‚¬ìš©í•˜ì—¬ PRì„ ë¦¬ë·°í•©ë‹ˆë‹¤.
+
+### ì™œ ë‘ ê°œì˜ AIë¥¼ ì‚¬ìš©í•˜ë‚˜ìš”?
+
+| AI | ê°•ì  | íŠ¹ì§• |
+|----|------|------|
+| **GLM-4-Flash** | ë¹ ë¥¸ ì‘ë‹µ, ì½”ë“œ ì´í•´ë ¥, ë¬´ë£Œ | Zhipu AI (ì¤‘êµ­) |
+| **Gemini 2.5 Flash** | ì•ˆì •ì„±, ë¹ ë¥¸ ì‘ë‹µ, ë„“ì€ ì»¨í…ìŠ¤íŠ¸ | Google |
+
+ë‘ AIê°€ **ë™ì‹œì— ì§€ì í•œ ì´ìŠˆ**ëŠ” ë†’ì€ ì‹ ë¢°ë„ë¥¼ ê°€ì§‘ë‹ˆë‹¤.
+
+---
+
+## ğŸ”‘ 1ë‹¨ê³„: API í‚¤ ë°œê¸‰
+
+### GLM API í‚¤ (Zhipu AI)
+
+1. [https://open.bigmodel.cn/](https://open.bigmodel.cn/) ì ‘ì†
+2. íšŒì›ê°€ì… (Zhipu AI ê³„ì • í•„ìš”)
+3. API Key ë°œê¸‰
+4. **ë¬´ë£Œ í•œë„**: ì‹ ê·œ ê°€ì… ì‹œ ë¬´ë£Œ í¬ë ˆë”§ ì œê³µ
+
+### Gemini API í‚¤ (Google)
+
+1. [https://aistudio.google.com/apikey](https://aistudio.google.com/apikey) ì ‘ì†
+2. Google ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸
+3. "Create API Key" í´ë¦­
+4. **ë¬´ë£Œ**: ì™„ì „ ë¬´ë£Œ (Rate limitë§Œ ì¡´ì¬)
+
+---
+
+## ğŸ”§ 2ë‹¨ê³„: GitHub Secrets ì„¤ì •
+
+Repository Settings â†’ Secrets and variables â†’ Actionsì—ì„œ ì¶”ê°€:
+
+| Secret ì´ë¦„ | ê°’ | í•„ìˆ˜ ì—¬ë¶€ |
+|------------|-----|----------|
+| `GLM_API_KEY` | Zhipu AI GLM API í‚¤ | ë‘˜ ì¤‘ í•˜ë‚˜ í•„ìˆ˜ |
+| `GEMINI_API_KEY` | Google Gemini API í‚¤ | ë‘˜ ì¤‘ í•˜ë‚˜ í•„ìˆ˜ |
+
+> **Note**: ë‘ í‚¤ ëª¨ë‘ ì„¤ì •í•˜ë©´ í•˜ì´ë¸Œë¦¬ë“œ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.
+> í•˜ë‚˜ë§Œ ì„¤ì •í•´ë„ í•´ë‹¹ AIë§Œìœ¼ë¡œ ë¦¬ë·°ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.
+
+---
+
+## ğŸ“ 3ë‹¨ê³„: íŒŒì¼ í™•ì¸
+
+ë‹¤ìŒ íŒŒì¼ë“¤ì´ í”„ë¡œì íŠ¸ì— ìˆëŠ”ì§€ í™•ì¸:
+
+```
+.github/
+â””â”€â”€ workflows/
+    â””â”€â”€ ai-code-review.yml    # GitHub Actions ì›Œí¬í”Œë¡œìš°
+
+script/
+â”œâ”€â”€ ai_pr_reviewer.py         # ë©”ì¸ ë¦¬ë·°ì–´ ìŠ¤í¬ë¦½íŠ¸
+â””â”€â”€ pr_analyzer.py            # ì •ì  ë¶„ì„ (ê¸°ì¡´)
+
+.claude/
+â””â”€â”€ agents/
+    â””â”€â”€ ai-pr-reviewer.md     # Claude ì—ì´ì „íŠ¸ ì •ì˜
+```
+
+---
+
+## ğŸš€ 4ë‹¨ê³„: í…ŒìŠ¤íŠ¸
+
+### ë¡œì»¬ í…ŒìŠ¤íŠ¸
+
+```bash
+# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (Linux/macOS)
+export GLM_API_KEY="your-glm-api-key"
+export GEMINI_API_KEY="your-gemini-api-key"
+
+# PowerShell (Windows)
+$env:GLM_API_KEY = "your-glm-api-key"
+$env:GEMINI_API_KEY = "your-gemini-api-key"
+
+# ë¡œì»¬ diffë¡œ í…ŒìŠ¤íŠ¸
+git diff main | python script/ai_pr_reviewer.py
+
+# PR ë²ˆí˜¸ë¡œ í…ŒìŠ¤íŠ¸ (gh CLI í•„ìš”)
+python script/ai_pr_reviewer.py --pr 123
+
+# ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥
+python script/ai_pr_reviewer.py --pr 123 \
+  --output review.md \
+  --json review.json
+
+# Geminië§Œ ì‚¬ìš©
+python script/ai_pr_reviewer.py --pr 123 --gemini-only
+
+# GLMë§Œ ì‚¬ìš©
+python script/ai_pr_reviewer.py --pr 123 --glm-only
+```
+
+### GitHub Actions í…ŒìŠ¤íŠ¸
+
+1. ìƒˆë¡œìš´ PR ìƒì„±
+2. Actions íƒ­ì—ì„œ "AI Code Review" ì›Œí¬í”Œë¡œìš° í™•ì¸
+3. PRì— ì½”ë©˜íŠ¸ë¡œ ë¦¬ë·° ê²°ê³¼ê°€ ê²Œì‹œë˜ëŠ”ì§€ í™•ì¸
+
+---
+
+## âš™ï¸ ê³ ê¸‰ ì„¤ì •
+
+### íŠ¹ì • ë¸Œëœì¹˜ë§Œ ë¦¬ë·°
+
+`.github/workflows/ai-code-review.yml` ìˆ˜ì •:
+
+```yaml
+on:
+  pull_request:
+    types: [opened, synchronize, reopened]
+    branches:
+      - main
+      - develop
+```
+
+### Draft PR ìŠ¤í‚µ
+
+ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤:
+```yaml
+if: github.event.pull_request.draft == false
+```
+
+### Critical ì´ìŠˆ ì‹œ ë¹Œë“œ ì‹¤íŒ¨
+
+ì›Œí¬í”Œë¡œìš°ì—ì„œ ì£¼ì„ í•´ì œ:
+```yaml
+if [ "$CRITICAL" -gt 0 ]; then
+  echo "::error::Found $CRITICAL critical issue(s)"
+  exit 1  # ì´ ì¤„ ì£¼ì„ í•´ì œ
+fi
+```
+
+### Tech Stack ì»¤ìŠ¤í„°ë§ˆì´ì§•
+
+`script/ai_pr_reviewer.py`ì˜ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •:
+
+```python
+Tech Stack:
+- Backend: Kotlin + Spring Boot 3.2 + PostgreSQL + MongoDB + Redis
+- Frontend: Next.js + TypeScript + TailwindCSS
+- Mobile: Android (Jetpack Compose), iOS (UIKit/SwiftUI)
+```
+
+---
+
+## ğŸ“Š ë¦¬ë·° ê²°ê³¼ í•´ì„
+
+### Severity ë ˆë²¨
+
+| ë ˆë²¨ | ì•„ì´ì½˜ | ì˜ë¯¸ | ì•¡ì…˜ |
+|------|-------|------|------|
+| Critical | ğŸ”´ | ë³´ì•ˆ, í¬ë˜ì‹œ, ë°ì´í„° ì†ì‹¤ | **ë°˜ë“œì‹œ ìˆ˜ì •** |
+| High | ğŸŸ  | ì„±ëŠ¥, ì•„í‚¤í…ì²˜ ë¬¸ì œ | ìˆ˜ì • ê¶Œì¥ |
+| Medium | ğŸŸ¡ | ìŠ¤íƒ€ì¼, ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ | ê²€í†  í•„ìš” |
+| Low | ğŸŸ¢ | ì œì•ˆ, ê°œì„ ì‚¬í•­ | ì„ íƒì  |
+
+### Consensus Issues âš ï¸
+
+**ë‘ AIê°€ ëª¨ë‘ ì§€ì í•œ ì´ìŠˆ**ëŠ” íŠ¹ë³„íˆ í‘œì‹œë©ë‹ˆë‹¤:
+- ë†’ì€ ì‹ ë¢°ë„
+- ìš°ì„ ì ìœ¼ë¡œ ê²€í†  í•„ìš”
+- `ğŸ”¥ Consensus` íƒœê·¸ë¡œ í‘œì‹œ
+
+---
+
+## ğŸ” ë¬¸ì œ í•´ê²°
+
+### "No AI providers configured" ì˜¤ë¥˜
+
+```bash
+# í™˜ê²½ ë³€ìˆ˜ í™•ì¸ (Linux/macOS)
+echo $GLM_API_KEY
+echo $GEMINI_API_KEY
+
+# PowerShell (Windows)
+echo $env:GLM_API_KEY
+echo $env:GEMINI_API_KEY
+
+# GitHub Secrets í™•ì¸
+# Repository â†’ Settings â†’ Secrets â†’ Actions
+```
+
+### Rate Limit ì˜¤ë¥˜
+
+| Provider | ë¬´ë£Œ í•œë„ | í•´ê²°ì±… |
+|----------|----------|--------|
+| GLM | ê°€ì… ì‹œ ë¬´ë£Œ í¬ë ˆë”§ | ëŒ€ê¸° í›„ ì¬ì‹œë„ |
+| Gemini | 15 req/min | ëŒ€ê¸° í›„ ì¬ì‹œë„ |
+
+### í° PR ì²˜ë¦¬ ì‹¤íŒ¨
+
+Diffê°€ ë„ˆë¬´ í¬ë©´ ìë™ìœ¼ë¡œ ì˜ë¦½ë‹ˆë‹¤:
+- GLM: 30,000ì
+- Gemini: 50,000ì
+
+í•´ê²°ì±…:
+1. PRì„ ì‘ê²Œ ë‚˜ëˆ„ê¸°
+2. `pr_analyzer.py`ë¡œ ê³ ìœ„í—˜ íŒŒì¼ë§Œ ì„ ë³„í•˜ì—¬ ë¦¬ë·°
+
+---
+
+## ğŸ’° ë¹„ìš©
+
+**ì™„ì „ ë¬´ë£Œ!**
+
+| Provider | ë¬´ë£Œ í•œë„ | ì›” ë¹„ìš© |
+|----------|----------|--------|
+| GLM-4-Flash | ê°€ì… ì‹œ ë¬´ë£Œ í¬ë ˆë”§ | **$0** |
+| Gemini | ë¬´ì œí•œ (rate limitë§Œ) | **$0** |
+
+---
+
+## ğŸ“š ê´€ë ¨ ë¬¸ì„œ
+
+- [GLM-4 API ë¬¸ì„œ](https://open.bigmodel.cn/dev/api)
+- [Gemini API ë¬¸ì„œ](https://ai.google.dev/gemini-api/docs)
+- [GitHub Actions ë¬¸ì„œ](https://docs.github.com/actions)
+- [FanPulse PR ê°€ì´ë“œ](./team_git_commit_convention_conventional_commits.md)
+
+---
+
+## ğŸ¤ ê¸°ì—¬
+
+ë²„ê·¸ ë¦¬í¬íŠ¸ë‚˜ ê°œì„  ì œì•ˆì€ GitHub Issuesë¡œ ë“±ë¡í•´ì£¼ì„¸ìš”.
+
+---
+
+**Created**: 2026-01-27
+**Updated**: 2026-01-27
+**Maintainer**: FanPulse Team
diff --git a/script/ai_pr_reviewer.py b/script/ai_pr_reviewer.py
new file mode 100644
index 0000000..6be93bb
--- /dev/null
+++ b/script/ai_pr_reviewer.py
@@ -0,0 +1,1208 @@
+#!/usr/bin/env python3
+"""
+AI PR Code Reviewer - Hybrid (GLM + Gemini)
+===========================================
+
+GLM-4-Flashì™€ Gemini 2.5 Flashë¥¼ ë™ì‹œì— ì‚¬ìš©í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ PR ì½”ë“œ ë¦¬ë·° ë´‡.
+ë‘ AIì˜ ë¦¬ë·°ë¥¼ ë³‘í•©í•˜ì—¬ ë” ì •í™•í•˜ê³  í¬ê´„ì ì¸ ì½”ë“œ ë¦¬ë·°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
+
+Features:
+- ğŸ”¥ GLM-4-Flash (Zhipu AI): ë¹ ë¥´ê³  íš¨ìœ¨ì ì¸ ì½”ë“œ ë¶„ì„
+- âš¡ Gemini 2.5 Flash: ì•ˆì •ì„± + ë¹ ë¥¸ ì‘ë‹µ + 1M ì»¨í…ìŠ¤íŠ¸
+- ğŸ”„ ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ë¹ ë¥¸ ë¦¬ë·°
+- ğŸ“Š ë‘ AI ì˜ê²¬ ë³‘í•© ë° í•©ì˜ ë„ì¶œ
+- ğŸ›¡ï¸ í´ë°± ì§€ì› (í•œ ìª½ ì‹¤íŒ¨ ì‹œ ë‹¤ë¥¸ ìª½ ì‚¬ìš©)
+- ğŸ“¦ íŒŒì¼ë³„ ì²­í‚¹: í° diffë¥¼ ìë™ìœ¼ë¡œ íŒŒì¼ë³„ë¡œ ë¶„ë¦¬í•˜ì—¬ ë¦¬ë·°
+
+Usage:
+    # ê¸°ë³¸ ì‚¬ìš©
+    python script/ai_pr_reviewer.py --pr 123
+    python script/ai_pr_reviewer.py --diff "$(git diff main)"
+
+    # ë‹¨ì¼ AIë§Œ ì‚¬ìš©
+    python script/ai_pr_reviewer.py --pr 123 --gemini-only
+    python script/ai_pr_reviewer.py --pr 123 --glm-only
+
+    # ì²­í‚¹ ì œì–´
+    python script/ai_pr_reviewer.py --pr 123 --no-chunk        # ì²­í‚¹ ë¹„í™œì„±í™”
+    python script/ai_pr_reviewer.py --pr 123 --chunk-threshold 50000  # ì„ê³„ê°’ ë³€ê²½
+
+Environment Variables:
+    GLM_API_KEY: Zhipu AI API í‚¤ (ë˜ëŠ” ZHIPU_API_KEY)
+    GEMINI_API_KEY: Google Gemini API í‚¤ (ë˜ëŠ” GOOGLE_API_KEY)
+    GITHUB_TOKEN: GitHub API í† í° (PR ì½”ë©˜íŠ¸ìš©)
+"""
+
+import os
+import json
+import subprocess
+import argparse
+import asyncio
+from pathlib import Path
+from typing import Dict, List, Any, Optional, Tuple
+from dataclasses import dataclass, asdict, field
+from enum import Enum
+from concurrent.futures import ThreadPoolExecutor, as_completed
+import re
+
+# Optional imports - graceful degradation
+import sys
+import io
+
+# Windows ì½˜ì†” ì¸ì½”ë”© ë¬¸ì œ í•´ê²°
+if sys.platform == 'win32':
+    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
+    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')
+
+try:
+    import google.generativeai as genai
+    GEMINI_AVAILABLE = True
+except ImportError:
+    GEMINI_AVAILABLE = False
+    print("[WARN] google-generativeai not installed. Gemini will be disabled.")
+
+try:
+    from openai import OpenAI
+    OPENAI_AVAILABLE = True
+except ImportError:
+    OPENAI_AVAILABLE = False
+    print("[WARN] openai package not installed. GLM will be disabled.")
+
+
+# ============================================================================
+# Diff Chunking - íŒŒì¼ë³„ ë¶„ë¦¬
+# ============================================================================
+
+@dataclass
+class DiffChunk:
+    """íŒŒì¼ë³„ diff ì²­í¬"""
+    file_path: str
+    content: str
+    size: int
+
+    @property
+    def is_code_file(self) -> bool:
+        """ì½”ë“œ íŒŒì¼ ì—¬ë¶€ (ë¦¬ë·° ëŒ€ìƒ)"""
+        code_extensions = {'.kt', '.java', '.py', '.ts', '.tsx', '.js', '.jsx', '.swift', '.go', '.rs'}
+        return any(self.file_path.endswith(ext) for ext in code_extensions)
+
+
+def parse_diff_by_files(diff: str) -> List[DiffChunk]:
+    """
+    Git diffë¥¼ íŒŒì¼ë³„ë¡œ ë¶„ë¦¬
+
+    Returns:
+        List[DiffChunk]: íŒŒì¼ë³„ diff ì²­í¬ ë¦¬ìŠ¤íŠ¸
+    """
+    chunks = []
+
+    # diff --git a/path/file b/path/file íŒ¨í„´ìœ¼ë¡œ ë¶„ë¦¬
+    pattern = r'^diff --git a/(.+?) b/(.+?)$'
+
+    # ê° íŒŒì¼ì˜ ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸°
+    file_starts = []
+    for match in re.finditer(pattern, diff, re.MULTILINE):
+        file_starts.append({
+            'start': match.start(),
+            'file_path': match.group(2)  # b/path ì‚¬ìš©
+        })
+
+    if not file_starts:
+        # diff í˜•ì‹ì´ ì•„ë‹Œ ê²½ìš° ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì²­í¬ë¡œ
+        return [DiffChunk(file_path="unknown", content=diff, size=len(diff))]
+
+    # ê° íŒŒì¼ì˜ diff ë‚´ìš© ì¶”ì¶œ
+    for i, file_info in enumerate(file_starts):
+        start = file_info['start']
+        end = file_starts[i + 1]['start'] if i + 1 < len(file_starts) else len(diff)
+
+        content = diff[start:end].strip()
+        chunks.append(DiffChunk(
+            file_path=file_info['file_path'],
+            content=content,
+            size=len(content)
+        ))
+
+    return chunks
+
+
+def group_chunks_by_size(chunks: List[DiffChunk], max_size: int = 30000) -> List[List[DiffChunk]]:
+    """
+    ì²­í¬ë“¤ì„ max_size ì´í•˜ë¡œ ê·¸ë£¹í™”
+
+    Args:
+        chunks: íŒŒì¼ë³„ diff ì²­í¬ ë¦¬ìŠ¤íŠ¸
+        max_size: ê·¸ë£¹ë‹¹ ìµœëŒ€ í¬ê¸° (ê¸°ë³¸ 30KB)
+
+    Returns:
+        ê·¸ë£¹í™”ëœ ì²­í¬ ë¦¬ìŠ¤íŠ¸
+    """
+    groups = []
+    current_group = []
+    current_size = 0
+
+    # ì½”ë“œ íŒŒì¼ë§Œ í•„í„°ë§ (ì„¤ì • íŒŒì¼ ë“± ì œì™¸)
+    code_chunks = [c for c in chunks if c.is_code_file]
+
+    # í¬ê¸°ìˆœ ì •ë ¬ (í° íŒŒì¼ ë¨¼ì € - bin packing)
+    sorted_chunks = sorted(code_chunks, key=lambda x: x.size, reverse=True)
+
+    for chunk in sorted_chunks:
+        # ë‹¨ì¼ íŒŒì¼ì´ max_size ì´ˆê³¼í•˜ë©´ ë³„ë„ ê·¸ë£¹
+        if chunk.size > max_size:
+            if current_group:
+                groups.append(current_group)
+                current_group = []
+                current_size = 0
+            groups.append([chunk])
+            continue
+
+        # í˜„ì¬ ê·¸ë£¹ì— ì¶”ê°€ ê°€ëŠ¥í•˜ë©´ ì¶”ê°€
+        if current_size + chunk.size <= max_size:
+            current_group.append(chunk)
+            current_size += chunk.size
+        else:
+            # ìƒˆ ê·¸ë£¹ ì‹œì‘
+            if current_group:
+                groups.append(current_group)
+            current_group = [chunk]
+            current_size = chunk.size
+
+    if current_group:
+        groups.append(current_group)
+
+    return groups
+
+
+def merge_chunks_to_diff(chunks: List[DiffChunk]) -> str:
+    """ì²­í¬ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ diff ë¬¸ìì—´ë¡œ ë³‘í•©"""
+    return "\n\n".join(chunk.content for chunk in chunks)
+
+
+class Severity(Enum):
+    """ë¦¬ë·° ì´ìŠˆ ì‹¬ê°ë„"""
+    CRITICAL = "critical"  # ğŸ”´ ë³´ì•ˆ, ë²„ê·¸, í¬ë˜ì‹œ
+    HIGH = "high"          # ğŸŸ  ì„±ëŠ¥, ì•„í‚¤í…ì²˜
+    MEDIUM = "medium"      # ğŸŸ¡ ì½”ë“œ ìŠ¤íƒ€ì¼, ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤
+    LOW = "low"            # ğŸŸ¢ ì œì•ˆ, ê°œì„ ì‚¬í•­
+    INFO = "info"          # â„¹ï¸ ì •ë³´ì„± ì½”ë©˜íŠ¸
+
+
+@dataclass
+class ReviewIssue:
+    """ì½”ë“œ ë¦¬ë·° ì´ìŠˆ"""
+    file_path: str
+    line_number: Optional[int]
+    severity: Severity
+    category: str  # security, performance, bug, style, suggestion
+    title: str
+    description: str
+    suggestion: Optional[str] = None
+    source: str = "unknown"  # glm, gemini, merged
+
+
+@dataclass
+class ReviewResult:
+    """AI ë¦¬ë·° ê²°ê³¼"""
+    provider: str
+    success: bool
+    issues: List[ReviewIssue] = field(default_factory=list)
+    summary: str = ""
+    raw_response: str = ""
+    error: Optional[str] = None
+
+
+@dataclass
+class MergedReview:
+    """ë³‘í•©ëœ ìµœì¢… ë¦¬ë·°"""
+    glm_result: Optional[ReviewResult]
+    gemini_result: Optional[ReviewResult]
+    merged_issues: List[ReviewIssue] = field(default_factory=list)
+    consensus_issues: List[ReviewIssue] = field(default_factory=list)  # ë‘ AI ëª¨ë‘ ì§€ì 
+    summary: str = ""
+    stats: Dict[str, int] = field(default_factory=dict)
+
+
+class GLMReviewer:
+    """GLM-4-Flash ê¸°ë°˜ ì½”ë“œ ë¦¬ë·°ì–´ (Zhipu AI)"""
+
+    def __init__(self, api_key: Optional[str] = None):
+        self.api_key = api_key or os.environ.get("GLM_API_KEY") or os.environ.get("ZHIPU_API_KEY")
+        self.client = None
+
+        if self.api_key and OPENAI_AVAILABLE:
+            # GLMì€ OpenAI í˜¸í™˜ API ì œê³µ
+            self.client = OpenAI(
+                api_key=self.api_key,
+                base_url="https://open.bigmodel.cn/api/paas/v4/"
+            )
+    
+    @property
+    def is_available(self) -> bool:
+        return self.client is not None
+    
+    def review(self, diff: str, context: Dict[str, Any] = None) -> ReviewResult:
+        """GLMìœ¼ë¡œ ì½”ë“œ ë¦¬ë·° ìˆ˜í–‰"""
+        if not self.is_available:
+            return ReviewResult(
+                provider="glm",
+                success=False,
+                error="GLM API not configured"
+            )
+
+        try:
+            prompt = self._build_prompt(diff, context)
+
+            response = self.client.chat.completions.create(
+                model="glm-4-flash",
+                messages=[
+                    {"role": "system", "content": self._get_system_prompt()},
+                    {"role": "user", "content": prompt}
+                ],
+                max_tokens=4096,
+                temperature=0.1
+            )
+
+            raw_response = response.choices[0].message.content
+            issues = self._parse_response(raw_response)
+
+            return ReviewResult(
+                provider="glm",
+                success=True,
+                issues=issues,
+                summary=self._extract_summary(raw_response),
+                raw_response=raw_response
+            )
+            
+        except Exception as e:
+            return ReviewResult(
+                provider="glm",
+                success=False,
+                error=str(e)
+            )
+    
+    def _get_system_prompt(self) -> str:
+        return """You are an expert code reviewer for FanPulse, a K-POP fan platform.
+
+Tech Stack:
+- Backend: Kotlin + Spring Boot 3.2 + PostgreSQL + MongoDB + Redis
+- Frontend: Next.js + TypeScript + TailwindCSS
+- Mobile: Android (Jetpack Compose), iOS (UIKit/SwiftUI)
+
+Review Guidelines:
+1. Focus on REAL bugs and security issues first
+2. Check for performance problems (N+1 queries, memory leaks)
+3. Verify error handling and edge cases
+4. Suggest improvements for code quality
+
+Output Format (JSON):
+{
+  "summary": "Brief overall assessment",
+  "issues": [
+    {
+      "file": "path/to/file.kt",
+      "line": 42,
+      "severity": "critical|high|medium|low",
+      "category": "security|bug|performance|style|suggestion",
+      "title": "Short issue title",
+      "description": "Detailed explanation",
+      "suggestion": "How to fix (optional)"
+    }
+  ]
+}
+
+Be specific with file paths and line numbers when possible.
+Focus on actionable feedback, not nitpicks."""
+    
+    def _build_prompt(self, diff: str, context: Dict[str, Any] = None) -> str:
+        MAX_DIFF_SIZE = 30000
+        truncated = len(diff) > MAX_DIFF_SIZE
+
+        if truncated:
+            print(f"[WARN] GLM: Diff truncated ({len(diff)} -> {MAX_DIFF_SIZE} chars)")
+            diff_content = diff[:MAX_DIFF_SIZE] + "\n\n[... truncated, showing first 30KB ...]"
+        else:
+            diff_content = diff
+
+        prompt = f"Review this code change:\n\n```diff\n{diff_content}\n```"
+
+        if context:
+            if context.get("pr_title"):
+                prompt = f"PR: {context['pr_title']}\n\n" + prompt
+            if context.get("pr_description"):
+                prompt += f"\n\nPR Description: {context['pr_description']}"
+
+        return prompt
+    
+    def _parse_response(self, response: str) -> List[ReviewIssue]:
+        """ì‘ë‹µì—ì„œ ì´ìŠˆ íŒŒì‹±"""
+        issues = []
+        data = self._extract_json(response)
+
+        if data:
+            for item in data.get("issues", []):
+                try:
+                    issues.append(ReviewIssue(
+                        file_path=item.get("file", "unknown"),
+                        line_number=item.get("line"),
+                        severity=Severity(item.get("severity", "medium")),
+                        category=item.get("category", "suggestion"),
+                        title=item.get("title", ""),
+                        description=item.get("description", ""),
+                        suggestion=item.get("suggestion"),
+                        source="glm"
+                    ))
+                except (ValueError, KeyError) as e:
+                    print(f"[WARN] Skipping invalid issue: {e}")
+
+        return issues
+    
+    def _extract_json(self, response: str) -> Optional[dict]:
+        """ì‘ë‹µì—ì„œ JSON ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
+        # 1. JSON ì½”ë“œ ë¸”ë¡ ìš°ì„  ì‹œë„
+        json_block = re.search(r'```json\s*(\{[\s\S]*?\})\s*```', response)
+        if json_block:
+            try:
+                return json.loads(json_block.group(1))
+            except json.JSONDecodeError:
+                pass
+
+        # 2. ì²« ë²ˆì§¸ ìœ íš¨í•œ JSON ê°ì²´ ì°¾ê¸° (balanced braces)
+        start = response.find('{')
+        if start == -1:
+            return None
+
+        depth = 0
+        for i in range(start, len(response)):
+            if response[i] == '{':
+                depth += 1
+            elif response[i] == '}':
+                depth -= 1
+                if depth == 0:
+                    try:
+                        return json.loads(response[start:i + 1])
+                    except json.JSONDecodeError:
+                        # ì´ JSONì´ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ë‹¤ìŒ ì‹œì‘ì  ì°¾ê¸°
+                        start = response.find('{', i + 1)
+                        if start == -1:
+                            return None
+                        depth = 0
+                        continue
+        return None
+
+    def _extract_summary(self, response: str) -> str:
+        """ì‘ë‹µì—ì„œ ìš”ì•½ ì¶”ì¶œ"""
+        data = self._extract_json(response)
+        if data:
+            return data.get("summary", "")
+        return ""
+
+
+class GeminiReviewer:
+    """Google Gemini 2.5 Flash ê¸°ë°˜ ì½”ë“œ ë¦¬ë·°ì–´"""
+    
+    def __init__(self, api_key: Optional[str] = None):
+        self.api_key = api_key or os.environ.get("GEMINI_API_KEY") or os.environ.get("GOOGLE_API_KEY")
+        self.model = None
+        
+        if self.api_key and GEMINI_AVAILABLE:
+            genai.configure(api_key=self.api_key)
+            self.model = genai.GenerativeModel('gemini-2.5-flash')
+    
+    @property
+    def is_available(self) -> bool:
+        return self.model is not None
+    
+    def review(self, diff: str, context: Dict[str, Any] = None) -> ReviewResult:
+        """Geminië¡œ ì½”ë“œ ë¦¬ë·° ìˆ˜í–‰"""
+        if not self.is_available:
+            return ReviewResult(
+                provider="gemini",
+                success=False,
+                error="Gemini API not configured"
+            )
+        
+        try:
+            prompt = self._build_prompt(diff, context)
+            
+            response = self.model.generate_content(
+                prompt,
+                generation_config=genai.GenerationConfig(
+                    temperature=0.1,
+                    max_output_tokens=4096
+                )
+            )
+            
+            raw_response = response.text
+
+            # ë””ë²„ê¹…: raw response ì¶œë ¥
+            print(f"[DEBUG] Gemini raw response length: {len(raw_response)} chars")
+            if len(raw_response) < 500:
+                print(f"[DEBUG] Full response: {raw_response}")
+            else:
+                print(f"[DEBUG] Response preview: {raw_response[:500]}...")
+
+            issues = self._parse_response(raw_response)
+            
+            return ReviewResult(
+                provider="gemini",
+                success=True,
+                issues=issues,
+                summary=self._extract_summary(raw_response),
+                raw_response=raw_response
+            )
+            
+        except Exception as e:
+            return ReviewResult(
+                provider="gemini",
+                success=False,
+                error=str(e)
+            )
+    
+    def _build_prompt(self, diff: str, context: Dict[str, Any] = None) -> str:
+        system_context = """You are an expert code reviewer for FanPulse, a K-POP fan platform.
+
+Tech Stack:
+- Backend: Kotlin + Spring Boot 3.2 + PostgreSQL + MongoDB + Redis  
+- Frontend: Next.js + TypeScript + TailwindCSS
+- Mobile: Android (Jetpack Compose), iOS (UIKit/SwiftUI)
+
+Review Guidelines:
+1. Security vulnerabilities (SQL injection, XSS, auth bypass)
+2. Bug detection and edge cases
+3. Performance issues (N+1, memory leaks, inefficient algorithms)
+4. Code quality and maintainability
+5. Best practices for the tech stack
+
+Output Format (JSON):
+{
+  "summary": "Brief overall assessment",
+  "issues": [
+    {
+      "file": "path/to/file.kt",
+      "line": 42,
+      "severity": "critical|high|medium|low",
+      "category": "security|bug|performance|style|suggestion",
+      "title": "Short issue title",
+      "description": "Detailed explanation",
+      "suggestion": "How to fix (optional)"
+    }
+  ]
+}
+
+Be thorough but focus on significant issues. Avoid nitpicks."""
+        
+        MAX_DIFF_SIZE = 50000
+        truncated = len(diff) > MAX_DIFF_SIZE
+
+        if truncated:
+            print(f"âš ï¸  Gemini: Diff truncated ({len(diff)} â†’ {MAX_DIFF_SIZE} chars)")
+            diff_content = diff[:MAX_DIFF_SIZE] + "\n\n[... truncated, showing first 50KB ...]"
+        else:
+            diff_content = diff
+
+        prompt = f"{system_context}\n\n---\n\nReview this code change:\n\n```diff\n{diff_content}\n```"
+
+        if context:
+            if context.get("pr_title"):
+                prompt += f"\n\nPR Title: {context['pr_title']}"
+            if context.get("pr_description"):
+                prompt += f"\nPR Description: {context['pr_description']}"
+
+        return prompt
+    
+    def _parse_response(self, response: str) -> List[ReviewIssue]:
+        """ì‘ë‹µì—ì„œ ì´ìŠˆ íŒŒì‹±"""
+        issues = []
+        data = self._extract_json(response)
+
+        if data:
+            for item in data.get("issues", []):
+                try:
+                    issues.append(ReviewIssue(
+                        file_path=item.get("file", "unknown"),
+                        line_number=item.get("line"),
+                        severity=Severity(item.get("severity", "medium")),
+                        category=item.get("category", "suggestion"),
+                        title=item.get("title", ""),
+                        description=item.get("description", ""),
+                        suggestion=item.get("suggestion"),
+                        source="gemini"
+                    ))
+                except (ValueError, KeyError) as e:
+                    print(f"âš ï¸  Skipping invalid issue: {e}")
+
+        return issues
+
+    def _extract_json(self, response: str) -> Optional[dict]:
+        """ì‘ë‹µì—ì„œ JSON ì•ˆì „í•˜ê²Œ ì¶”ì¶œ"""
+        # 1. JSON ì½”ë“œ ë¸”ë¡ ìš°ì„  ì‹œë„
+        json_block = re.search(r'```json\s*(\{[\s\S]*?\})\s*```', response)
+        if json_block:
+            try:
+                return json.loads(json_block.group(1))
+            except json.JSONDecodeError:
+                pass
+
+        # 2. ì²« ë²ˆì§¸ ìœ íš¨í•œ JSON ê°ì²´ ì°¾ê¸° (balanced braces)
+        start = response.find('{')
+        if start == -1:
+            return None
+
+        depth = 0
+        for i in range(start, len(response)):
+            if response[i] == '{':
+                depth += 1
+            elif response[i] == '}':
+                depth -= 1
+                if depth == 0:
+                    try:
+                        return json.loads(response[start:i + 1])
+                    except json.JSONDecodeError:
+                        start = response.find('{', i + 1)
+                        if start == -1:
+                            return None
+                        depth = 0
+                        continue
+        return None
+
+    def _extract_summary(self, response: str) -> str:
+        """ì‘ë‹µì—ì„œ ìš”ì•½ ì¶”ì¶œ"""
+        data = self._extract_json(response)
+        if data:
+            return data.get("summary", "")
+        return ""
+
+
+class HybridReviewer:
+    """GLM + Gemini í•˜ì´ë¸Œë¦¬ë“œ ë¦¬ë·°ì–´"""
+
+    def __init__(self, glm_key: str = None, gemini_key: str = None):
+        self.glm = GLMReviewer(glm_key)
+        self.gemini = GeminiReviewer(gemini_key)
+
+    def review(self, diff: str, context: Dict[str, Any] = None, parallel: bool = True) -> MergedReview:
+        """ë‘ AIë¡œ ë™ì‹œì— ë¦¬ë·°í•˜ê³  ê²°ê³¼ ë³‘í•©"""
+
+        glm_result = None
+        gemini_result = None
+
+        if parallel and self.glm.is_available and self.gemini.is_available:
+            # ë³‘ë ¬ ì‹¤í–‰
+            with ThreadPoolExecutor(max_workers=2) as executor:
+                futures = {
+                    executor.submit(self.glm.review, diff, context): "glm",
+                    executor.submit(self.gemini.review, diff, context): "gemini"
+                }
+                
+                for future in as_completed(futures):
+                    provider = futures[future]
+                    try:
+                        result = future.result(timeout=120)
+                        if provider == "glm":
+                            glm_result = result
+                        else:
+                            gemini_result = result
+                    except Exception as e:
+                        print(f"[WARN] {provider} failed: {e}")
+        else:
+            # ìˆœì°¨ ì‹¤í–‰
+            if self.glm.is_available:
+                print("Running GLM review...")
+                glm_result = self.glm.review(diff, context)
+
+            if self.gemini.is_available:
+                print("Running Gemini review...")
+                gemini_result = self.gemini.review(diff, context)
+        
+        # ê²°ê³¼ ë³‘í•©
+        return self._merge_results(glm_result, gemini_result)
+
+    def _merge_results(self, glm: Optional[ReviewResult], gemini: Optional[ReviewResult]) -> MergedReview:
+        """ë‘ ë¦¬ë·° ê²°ê³¼ ë³‘í•©"""
+        merged = MergedReview(
+            glm_result=glm,
+            gemini_result=gemini
+        )
+
+        all_issues: List[ReviewIssue] = []
+        
+        # ì´ìŠˆ ìˆ˜ì§‘
+        if glm and glm.success:
+            all_issues.extend(glm.issues)
+        if gemini and gemini.success:
+            all_issues.extend(gemini.issues)
+        
+        # ì¤‘ë³µ ì œê±° ë° í•©ì˜ ì‹ë³„
+        seen = {}
+        for issue in all_issues:
+            key = f"{issue.file_path}:{issue.line_number}:{issue.category}"
+            
+            if key in seen:
+                # ë‘ AIê°€ ê°™ì€ ì´ìŠˆ ì§€ì  = í•©ì˜
+                existing = seen[key]
+                if existing.source != issue.source:
+                    # ì‹¬ê°ë„ëŠ” ë” ë†’ì€ ê²ƒ ì„ íƒ
+                    severity_order = [Severity.CRITICAL, Severity.HIGH, Severity.MEDIUM, Severity.LOW, Severity.INFO]
+                    if severity_order.index(issue.severity) < severity_order.index(existing.severity):
+                        existing.severity = issue.severity
+                    existing.source = "consensus"
+                    merged.consensus_issues.append(existing)
+            else:
+                seen[key] = issue
+        
+        # ì •ë ¬: í•©ì˜ ì´ìŠˆ > Critical > High > Medium > Low
+        merged.merged_issues = sorted(
+            seen.values(),
+            key=lambda x: (
+                x.source != "consensus",
+                [Severity.CRITICAL, Severity.HIGH, Severity.MEDIUM, Severity.LOW, Severity.INFO].index(x.severity)
+            )
+        )
+        
+        # í†µê³„
+        merged.stats = {
+            "total_issues": len(merged.merged_issues),
+            "consensus_issues": len(merged.consensus_issues),
+            "glm_only": len([i for i in merged.merged_issues if i.source == "glm"]),
+            "gemini_only": len([i for i in merged.merged_issues if i.source == "gemini"]),
+            "critical": len([i for i in merged.merged_issues if i.severity == Severity.CRITICAL]),
+            "high": len([i for i in merged.merged_issues if i.severity == Severity.HIGH]),
+            "medium": len([i for i in merged.merged_issues if i.severity == Severity.MEDIUM]),
+            "low": len([i for i in merged.merged_issues if i.severity == Severity.LOW]),
+        }
+        
+        # ìš”ì•½ ìƒì„±
+        merged.summary = self._generate_summary(merged)
+        
+        return merged
+    
+    def _generate_summary(self, merged: MergedReview) -> str:
+        """ë³‘í•©ëœ ë¦¬ë·° ìš”ì•½ ìƒì„±"""
+        parts = []
+        
+        if merged.stats["critical"] > 0:
+            parts.append(f"ğŸ”´ {merged.stats['critical']} critical issue(s)")
+        if merged.stats["high"] > 0:
+            parts.append(f"ğŸŸ  {merged.stats['high']} high priority issue(s)")
+        if merged.stats["medium"] > 0:
+            parts.append(f"ğŸŸ¡ {merged.stats['medium']} medium issue(s)")
+        if merged.stats["low"] > 0:
+            parts.append(f"ğŸŸ¢ {merged.stats['low']} suggestion(s)")
+        
+        if merged.stats["consensus_issues"] > 0:
+            parts.append(f"âš ï¸ {merged.stats['consensus_issues']} issue(s) flagged by BOTH AI reviewers")
+        
+        if not parts:
+            return "âœ… No significant issues found. LGTM!"
+
+        return " | ".join(parts)
+
+
+class ChunkedReviewer:
+    """
+    íŒŒì¼ë³„ ì²­í‚¹ì„ ì§€ì›í•˜ëŠ” ë¦¬ë·°ì–´
+
+    í° diffë¥¼ íŒŒì¼ë³„ë¡œ ë‚˜ëˆ ì„œ ë³‘ë ¬ë¡œ ë¦¬ë·°í•˜ê³  ê²°ê³¼ë¥¼ ë³‘í•©í•©ë‹ˆë‹¤.
+    """
+
+    # ì²­í‚¹ ì„ê³„ê°’ (ì´ í¬ê¸° ì´ìƒì´ë©´ íŒŒì¼ë³„ ë¶„ë¦¬)
+    CHUNK_THRESHOLD = 40000  # 40KB
+    MAX_CHUNK_SIZE = 30000   # ê° ì²­í¬ ìµœëŒ€ 30KB
+    MAX_PARALLEL_CHUNKS = 5  # ë™ì‹œ ë¦¬ë·° ìµœëŒ€ ì²­í¬ ìˆ˜
+
+    def __init__(self, glm_key: str = None, gemini_key: str = None):
+        self.hybrid = HybridReviewer(glm_key, gemini_key)
+        self.glm = self.hybrid.glm
+        self.gemini = self.hybrid.gemini
+
+    def review(
+        self,
+        diff: str,
+        context: Dict[str, Any] = None,
+        use_glm: bool = True,
+        use_gemini: bool = True
+    ) -> MergedReview:
+        """
+        ìŠ¤ë§ˆíŠ¸ ë¦¬ë·°: í¬ê¸°ì— ë”°ë¼ ì¼ë°˜/ì²­í‚¹ ë°©ì‹ ì„ íƒ
+
+        Args:
+            diff: Git diff ë‚´ìš©
+            context: PR ì •ë³´ (title, description ë“±)
+            use_glm: GLM ì‚¬ìš© ì—¬ë¶€
+            use_gemini: Gemini ì‚¬ìš© ì—¬ë¶€
+        """
+        diff_size = len(diff)
+
+        # ì‘ì€ diffëŠ” ì¼ë°˜ ë¦¬ë·°
+        if diff_size < self.CHUNK_THRESHOLD:
+            print(f"ğŸ“ ì¼ë°˜ ë¦¬ë·° ëª¨ë“œ (diff: {diff_size:,} chars)")
+            return self._single_review(diff, context, use_glm, use_gemini)
+
+        # í° diffëŠ” ì²­í‚¹ ë¦¬ë·°
+        print(f"ğŸ“¦ ì²­í‚¹ ë¦¬ë·° ëª¨ë“œ (diff: {diff_size:,} chars, threshold: {self.CHUNK_THRESHOLD:,})")
+        return self._chunked_review(diff, context, use_glm, use_gemini)
+
+    def _single_review(
+        self,
+        diff: str,
+        context: Dict[str, Any],
+        use_glm: bool,
+        use_gemini: bool
+    ) -> MergedReview:
+        """ì¼ë°˜ ë¦¬ë·° (ì²­í‚¹ ì—†ìŒ)"""
+        if use_glm and use_gemini:
+            return self.hybrid.review(diff, context)
+        elif use_glm:
+            result = self.glm.review(diff, context)
+            return self._wrap_single_result(result, "glm")
+        elif use_gemini:
+            result = self.gemini.review(diff, context)
+            return self._wrap_single_result(result, "gemini")
+        else:
+            return MergedReview(glm_result=None, gemini_result=None)
+
+    def _chunked_review(
+        self,
+        diff: str,
+        context: Dict[str, Any],
+        use_glm: bool,
+        use_gemini: bool
+    ) -> MergedReview:
+        """íŒŒì¼ë³„ ì²­í‚¹ ë¦¬ë·°"""
+        # 1. íŒŒì¼ë³„ë¡œ diff ë¶„ë¦¬
+        chunks = parse_diff_by_files(diff)
+        code_chunks = [c for c in chunks if c.is_code_file]
+
+        print(f"   ğŸ“ ì´ {len(chunks)}ê°œ íŒŒì¼ ì¤‘ {len(code_chunks)}ê°œ ì½”ë“œ íŒŒì¼ ë°œê²¬")
+
+        if not code_chunks:
+            print("   âš ï¸ ë¦¬ë·°í•  ì½”ë“œ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
+            return MergedReview(
+                glm_result=None,
+                gemini_result=None,
+                summary="No code files to review"
+            )
+
+        # 2. í¬ê¸° ê¸°ì¤€ìœ¼ë¡œ ê·¸ë£¹í™”
+        groups = group_chunks_by_size(code_chunks, self.MAX_CHUNK_SIZE)
+        print(f"   ğŸ“¦ {len(groups)}ê°œ ê·¸ë£¹ìœ¼ë¡œ ë¶„í• ")
+
+        # 3. ê° ê·¸ë£¹ë³„ ë³‘ë ¬ ë¦¬ë·°
+        all_issues: List[ReviewIssue] = []
+
+        # ë™ì‹œ ì‹¤í–‰ ì œí•œ
+        groups_to_review = groups[:self.MAX_PARALLEL_CHUNKS]
+        if len(groups) > self.MAX_PARALLEL_CHUNKS:
+            print(f"   âš ï¸ {len(groups) - self.MAX_PARALLEL_CHUNKS}ê°œ ê·¸ë£¹ ìŠ¤í‚µ (ìµœëŒ€ {self.MAX_PARALLEL_CHUNKS}ê°œ)")
+
+        with ThreadPoolExecutor(max_workers=self.MAX_PARALLEL_CHUNKS) as executor:
+            futures = {}
+
+            for i, group in enumerate(groups_to_review):
+                group_diff = merge_chunks_to_diff(group)
+                file_names = [c.file_path for c in group]
+
+                print(f"   ğŸ” ê·¸ë£¹ {i+1}: {len(group)}ê°œ íŒŒì¼ ({len(group_diff):,} chars)")
+                for name in file_names[:3]:  # ìµœëŒ€ 3ê°œë§Œ ì¶œë ¥
+                    print(f"      - {name}")
+                if len(file_names) > 3:
+                    print(f"      ... ì™¸ {len(file_names) - 3}ê°œ")
+
+                # ë¦¬ë·° ì œì¶œ
+                future = executor.submit(
+                    self._review_chunk,
+                    group_diff,
+                    context,
+                    use_glm,
+                    use_gemini
+                )
+                futures[future] = i
+
+            # ê²°ê³¼ ìˆ˜ì§‘
+            for future in as_completed(futures):
+                group_idx = futures[future]
+                try:
+                    result = future.result(timeout=180)  # 3ë¶„ íƒ€ì„ì•„ì›ƒ
+                    issues = result.merged_issues if hasattr(result, 'merged_issues') else []
+                    all_issues.extend(issues)
+                    print(f"   âœ… ê·¸ë£¹ {group_idx + 1} ì™„ë£Œ: {len(issues)}ê°œ ì´ìŠˆ")
+                except Exception as e:
+                    print(f"   âŒ ê·¸ë£¹ {group_idx + 1} ì‹¤íŒ¨: {e}")
+
+        # 4. ê²°ê³¼ ë³‘í•©
+        return self._merge_chunked_results(all_issues, use_glm, use_gemini)
+
+    def _review_chunk(
+        self,
+        diff: str,
+        context: Dict[str, Any],
+        use_glm: bool,
+        use_gemini: bool
+    ) -> MergedReview:
+        """ë‹¨ì¼ ì²­í¬ ë¦¬ë·°"""
+        return self._single_review(diff, context, use_glm, use_gemini)
+
+    def _wrap_single_result(self, result: ReviewResult, provider: str) -> MergedReview:
+        """ë‹¨ì¼ ë¦¬ë·° ê²°ê³¼ë¥¼ MergedReviewë¡œ ë˜í•‘"""
+        merged = MergedReview(
+            glm_result=result if provider == "glm" else None,
+            gemini_result=result if provider == "gemini" else None
+        )
+        merged.merged_issues = result.issues if result.success else []
+        merged.summary = result.summary if result.success else (result.error or "Review failed")
+        merged.stats = {
+            "total_issues": len(merged.merged_issues),
+            "consensus_issues": 0,
+            "glm_only": len(merged.merged_issues) if provider == "glm" else 0,
+            "gemini_only": len(merged.merged_issues) if provider == "gemini" else 0,
+            "critical": len([i for i in merged.merged_issues if i.severity == Severity.CRITICAL]),
+            "high": len([i for i in merged.merged_issues if i.severity == Severity.HIGH]),
+            "medium": len([i for i in merged.merged_issues if i.severity == Severity.MEDIUM]),
+            "low": len([i for i in merged.merged_issues if i.severity == Severity.LOW]),
+        }
+        return merged
+
+    def _merge_chunked_results(
+        self,
+        all_issues: List[ReviewIssue],
+        use_glm: bool,
+        use_gemini: bool
+    ) -> MergedReview:
+        """ì²­í‚¹ëœ ëª¨ë“  ê²°ê³¼ ë³‘í•©"""
+        # ì¤‘ë³µ ì œê±° (ê°™ì€ íŒŒì¼, ê°™ì€ ë¼ì¸, ê°™ì€ ì¹´í…Œê³ ë¦¬)
+        seen = {}
+        for issue in all_issues:
+            key = f"{issue.file_path}:{issue.line_number}:{issue.category}:{issue.title[:30]}"
+            if key not in seen:
+                seen[key] = issue
+
+        unique_issues = list(seen.values())
+
+        # ì‹¬ê°ë„ìˆœ ì •ë ¬
+        severity_order = [Severity.CRITICAL, Severity.HIGH, Severity.MEDIUM, Severity.LOW, Severity.INFO]
+        sorted_issues = sorted(
+            unique_issues,
+            key=lambda x: severity_order.index(x.severity)
+        )
+
+        merged = MergedReview(glm_result=None, gemini_result=None)
+        merged.merged_issues = sorted_issues
+        merged.stats = {
+            "total_issues": len(sorted_issues),
+            "consensus_issues": len([i for i in sorted_issues if i.source == "consensus"]),
+            "glm_only": len([i for i in sorted_issues if i.source == "glm"]),
+            "gemini_only": len([i for i in sorted_issues if i.source == "gemini"]),
+            "critical": len([i for i in sorted_issues if i.severity == Severity.CRITICAL]),
+            "high": len([i for i in sorted_issues if i.severity == Severity.HIGH]),
+            "medium": len([i for i in sorted_issues if i.severity == Severity.MEDIUM]),
+            "low": len([i for i in sorted_issues if i.severity == Severity.LOW]),
+        }
+
+        # ìš”ì•½ ìƒì„±
+        parts = []
+        if merged.stats["critical"] > 0:
+            parts.append(f"ğŸ”´ {merged.stats['critical']} critical")
+        if merged.stats["high"] > 0:
+            parts.append(f"ğŸŸ  {merged.stats['high']} high")
+        if merged.stats["medium"] > 0:
+            parts.append(f"ğŸŸ¡ {merged.stats['medium']} medium")
+        if merged.stats["low"] > 0:
+            parts.append(f"ğŸŸ¢ {merged.stats['low']} low")
+
+        merged.summary = " | ".join(parts) if parts else "âœ… No significant issues found. LGTM!"
+
+        return merged
+
+
+def format_review_markdown(merged: MergedReview) -> str:
+    """ë¦¬ë·° ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í¬ë§·"""
+    lines = [
+        "# ğŸ¤– AI Code Review Results",
+        "",
+        f"**Reviewers:** GLM-4-Flash + Gemini 2.5 Flash (Hybrid)",
+        "",
+        f"## Summary",
+        f"{merged.summary}",
+        "",
+    ]
+    
+    # í†µê³„
+    lines.extend([
+        "### ğŸ“Š Statistics",
+        f"- Total Issues: {merged.stats['total_issues']}",
+        f"- Consensus (Both AIs agree): {merged.stats['consensus_issues']}",
+        f"- GLM only: {merged.stats['glm_only']}",
+        f"- Gemini only: {merged.stats['gemini_only']}",
+        "",
+    ])
+    
+    # í•©ì˜ëœ ì´ìŠˆ (ê°€ì¥ ì¤‘ìš”)
+    if merged.consensus_issues:
+        lines.extend([
+            "## âš ï¸ Consensus Issues (Both AIs Flagged)",
+            "_These issues were identified by both AI reviewers and should be prioritized._",
+            "",
+        ])
+        for issue in merged.consensus_issues:
+            lines.extend(format_issue_markdown(issue))
+    
+    # Critical ì´ìŠˆ
+    critical = [i for i in merged.merged_issues if i.severity == Severity.CRITICAL and i.source != "consensus"]
+    if critical:
+        lines.extend([
+            "## ğŸ”´ Critical Issues",
+            "",
+        ])
+        for issue in critical:
+            lines.extend(format_issue_markdown(issue))
+    
+    # High ì´ìŠˆ
+    high = [i for i in merged.merged_issues if i.severity == Severity.HIGH and i.source != "consensus"]
+    if high:
+        lines.extend([
+            "## ğŸŸ  High Priority",
+            "",
+        ])
+        for issue in high:
+            lines.extend(format_issue_markdown(issue))
+    
+    # Medium ì´ìŠˆ
+    medium = [i for i in merged.merged_issues if i.severity == Severity.MEDIUM and i.source != "consensus"]
+    if medium:
+        lines.extend([
+            "## ğŸŸ¡ Medium Priority",
+            "",
+        ])
+        for issue in medium:
+            lines.extend(format_issue_markdown(issue))
+    
+    # Low/Suggestions
+    low = [i for i in merged.merged_issues if i.severity in [Severity.LOW, Severity.INFO] and i.source != "consensus"]
+    if low:
+        lines.extend([
+            "## ğŸŸ¢ Suggestions",
+            "",
+        ])
+        for issue in low:
+            lines.extend(format_issue_markdown(issue))
+    
+    # Footer
+    lines.extend([
+        "",
+        "---",
+        "_Powered by GLM-4-Flash (Zhipu AI) + Gemini 2.5 Flash_",
+        "_Issues flagged by both AIs have higher confidence._",
+    ])
+    
+    return "\n".join(lines)
+
+
+def format_issue_markdown(issue: ReviewIssue) -> List[str]:
+    """ê°œë³„ ì´ìŠˆë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ í¬ë§·"""
+    source_badge = {
+        "glm": "ğŸ¤– GLM",
+        "gemini": "âœ¨ Gemini",
+        "consensus": "ğŸ”¥ Consensus"
+    }.get(issue.source, issue.source)
+    
+    location = f"`{issue.file_path}`"
+    if issue.line_number:
+        location += f" (line {issue.line_number})"
+    
+    lines = [
+        f"### {issue.title}",
+        f"**Location:** {location}",
+        f"**Category:** {issue.category} | **Source:** {source_badge}",
+        "",
+        issue.description,
+        "",
+    ]
+    
+    if issue.suggestion:
+        lines.extend([
+            "**Suggestion:**",
+            f"> {issue.suggestion}",
+            "",
+        ])
+    
+    return lines
+
+
+def get_pr_diff(pr_number: int) -> Tuple[str, Dict[str, Any]]:
+    """GitHub PRì˜ diffì™€ ì»¨í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°"""
+    try:
+        # PR ì •ë³´ ê°€ì ¸ì˜¤ê¸°
+        result = subprocess.run(
+            ["gh", "pr", "view", str(pr_number), "--json", "title,body,files"],
+            capture_output=True,
+            text=True,
+            timeout=30
+        )
+        
+        context = {}
+        if result.returncode == 0:
+            data = json.loads(result.stdout)
+            context = {
+                "pr_title": data.get("title", ""),
+                "pr_description": data.get("body", ""),
+            }
+        
+        # Diff ê°€ì ¸ì˜¤ê¸°
+        diff_result = subprocess.run(
+            ["gh", "pr", "diff", str(pr_number)],
+            capture_output=True,
+            text=True,
+            timeout=60
+        )
+        
+        return diff_result.stdout, context
+        
+    except Exception as e:
+        print(f"âš ï¸  Error fetching PR: {e}")
+        return "", {}
+
+
+def post_review_comment(pr_number: int, body: str) -> bool:
+    """PRì— ë¦¬ë·° ì½”ë©˜íŠ¸ ê²Œì‹œ"""
+    try:
+        result = subprocess.run(
+            ["gh", "pr", "comment", str(pr_number), "--body", body],
+            capture_output=True,
+            text=True,
+            timeout=30
+        )
+        return result.returncode == 0
+    except Exception as e:
+        print(f"âš ï¸  Error posting comment: {e}")
+        return False
+
+
+def main():
+    parser = argparse.ArgumentParser(description="AI PR Code Reviewer (GLM + Gemini Hybrid)")
+    parser.add_argument("--pr", type=int, help="GitHub PR number to review")
+    parser.add_argument("--diff", type=str, help="Direct diff content to review")
+    parser.add_argument("--diff-file", type=str, help="File containing diff to review")
+    parser.add_argument("--output", "-o", type=str, help="Output file for review (markdown)")
+    parser.add_argument("--json", type=str, help="Output file for raw JSON results")
+    parser.add_argument("--post-comment", action="store_true", help="Post review as PR comment")
+    parser.add_argument("--glm-only", action="store_true", help="Use only GLM")
+    parser.add_argument("--gemini-only", action="store_true", help="Use only Gemini")
+    parser.add_argument("--no-chunk", action="store_true", help="Disable file chunking for large diffs")
+    parser.add_argument("--chunk-threshold", type=int, default=40000,
+                       help="Diff size threshold for chunking (default: 40000 chars)")
+
+    args = parser.parse_args()
+    
+    # Diff ê°€ì ¸ì˜¤ê¸°
+    diff = ""
+    context = {}
+    
+    if args.pr:
+        print(f"ğŸ“¥ Fetching PR #{args.pr}...")
+        diff, context = get_pr_diff(args.pr)
+    elif args.diff:
+        diff = args.diff
+    elif args.diff_file:
+        diff = Path(args.diff_file).read_text(encoding='utf-8')
+    else:
+        # stdinì—ì„œ ì½ê¸°
+        print("ğŸ“¥ Reading diff from stdin...")
+        import sys
+        diff = sys.stdin.read()
+    
+    if not diff.strip():
+        print("âŒ No diff content provided")
+        return 1
+    
+    print(f"ğŸ“ Diff size: {len(diff):,} chars")
+
+    # ë¦¬ë·°ì–´ ì´ˆê¸°í™” (ì²­í‚¹ ì§€ì›)
+    reviewer = ChunkedReviewer()
+
+    # ì²­í‚¹ ì„¤ì • ì ìš©
+    if args.no_chunk:
+        reviewer.CHUNK_THRESHOLD = float('inf')  # ì²­í‚¹ ë¹„í™œì„±í™”
+        print("âš ï¸ ì²­í‚¹ ë¹„í™œì„±í™”ë¨ (--no-chunk)")
+    else:
+        reviewer.CHUNK_THRESHOLD = args.chunk_threshold
+
+    # ì‚¬ìš©í•  AI ê²°ì •
+    use_glm = not args.gemini_only
+    use_gemini = not args.glm_only
+
+    # API ê°€ìš©ì„± ì²´í¬
+    if use_glm and not reviewer.glm.is_available:
+        if args.glm_only:
+            print("âŒ GLM API not configured (GLM_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”)")
+            return 1
+        use_glm = False
+
+    if use_gemini and not reviewer.gemini.is_available:
+        if args.gemini_only:
+            print("âŒ Gemini API not configured (GEMINI_API_KEY í™˜ê²½ë³€ìˆ˜ í•„ìš”)")
+            return 1
+        use_gemini = False
+
+    if not use_glm and not use_gemini:
+        print("âŒ No AI providers configured. Set GLM_API_KEY or GEMINI_API_KEY")
+        return 1
+
+    # ì‚¬ìš©í•  AI í‘œì‹œ
+    providers = []
+    if use_glm:
+        providers.append("GLM-4-Flash")
+    if use_gemini:
+        providers.append("Gemini 2.5 Flash")
+    print(f"ğŸ” AI Reviewers: {', '.join(providers)}")
+
+    # ë¦¬ë·° ì‹¤í–‰ (ìë™ ì²­í‚¹)
+    merged = reviewer.review(diff, context, use_glm=use_glm, use_gemini=use_gemini)
+    
+    # ê²°ê³¼ ì¶œë ¥
+    print("\n" + "="*60)
+    print(merged.summary)
+    print("="*60 + "\n")
+    
+    # ë§ˆí¬ë‹¤ìš´ ìƒì„±
+    markdown = format_review_markdown(merged)
+    
+    # íŒŒì¼ ì¶œë ¥
+    if args.output:
+        Path(args.output).write_text(markdown)
+        print(f"ğŸ“„ Review saved to: {args.output}")
+    
+    if args.json:
+        json_data = {
+            "summary": merged.summary,
+            "stats": merged.stats,
+            "issues": [asdict(i) for i in merged.merged_issues],
+            "consensus_issues": [asdict(i) for i in merged.consensus_issues],
+        }
+        # Enum ì§ë ¬í™”
+        for issue in json_data["issues"] + json_data["consensus_issues"]:
+            issue["severity"] = issue["severity"].value if isinstance(issue["severity"], Severity) else issue["severity"]
+        
+        Path(args.json).write_text(json.dumps(json_data, indent=2, ensure_ascii=False))
+        print(f"ğŸ“„ JSON saved to: {args.json}")
+    
+    # PR ì½”ë©˜íŠ¸ ê²Œì‹œ
+    if args.post_comment and args.pr:
+        print(f"ğŸ’¬ Posting comment to PR #{args.pr}...")
+        if post_review_comment(args.pr, markdown):
+            print("âœ… Comment posted successfully")
+        else:
+            print("âŒ Failed to post comment")
+    
+    # ê¸°ë³¸ ì¶œë ¥
+    if not args.output and not args.json:
+        print(markdown)
+    
+    # Exit code: critical ì´ìŠˆê°€ ìˆìœ¼ë©´ 1
+    if merged.stats.get("critical", 0) > 0:
+        return 1
+    return 0
+
+
+if __name__ == "__main__":
+    exit(main())
